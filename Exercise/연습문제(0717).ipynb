{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071470/function-missing-required-argument-dest-pos-2\n",
      "function missing required argument 'dest' (pos 2)\n",
      "\n",
      "\n",
      "import pygame \n",
      "\n",
      "**function missing required argument 'dest' (pos 2) что это значит? У меня просто анимированый playerStand и я написала вот так else:\n",
      "        win.blit(playerStand[animCount // 5]), (x, y)\n",
      "        animCount += 1\n",
      "//win.blit(bg, (0, 0))\n",
      "  // pygame.display.update()\n",
      "и выдало ошибку dest.Обьясните кто-нибудь пожалуйста. Гуглила,какие-то проблемы с парсингом.**\n",
      "pygame.init()\n",
      "win = pygame.display.set_mode((1210, 750))\n",
      "\n",
      "pygame.display.set_caption(\"Cbes Game\")\n",
      "\n",
      "runRight = [pygame.image.load ('Run (1).png'),pygame.image.load ('Run \n",
      "(2).png'),pygame.image.load ('Run (3).png'),pygame.image.load ('Run \n",
      "(4).png'),pygame.image.load ('Run (5).png'),pygame.image.load ('Run \n",
      "(6).png'),pygame.image.load ('Run (7).png'),pygame.image.load ('Run \n",
      "(8).png'),pygame.image.load ('Run (9).png'),pygame.image.load ('Run \n",
      "(10).png'),pygame.image.load ('Run (11).png'),pygame.image.load ('Run \n",
      "(12).png'),pygame.image.load ('Run (13).png'),pygame.image.load ('Run \n",
      "(14).png'),pygame.image.load ('Run (15).png'),pygame.image.load ('Run \n",
      "(16).png'),pygame.image.load ('Run (17).png'),pygame.image.load ('Run \n",
      "(18).png'),pygame.image.load ('Run (19).png'),pygame.image.load ('Run \n",
      "(20).png')]\n",
      "\n",
      "runLeft = [pygame.image.load ('runLEFT(1).png'),pygame.image.load \n",
      "('runLEFT(2).png'),pygame.image.load ('runLEFT(3).png'),pygame.image.load \n",
      "('runLEFT(4).png'),pygame.image.load ('runLEFT(5).png'),pygame.image.load \n",
      "('runLEFT(6).png'),pygame.image.load ('runLEFT(7).png'),pygame.image.load \n",
      "('runLEFT(8).png'),pygame.image.load ('runLEFT(9).png'),pygame.image.load \n",
      "('runLEFT(10).png'),pygame.image.load \n",
      "('runLEFT(11).png'),pygame.image.load \n",
      "('runLEFT(12).png'),pygame.image.load \n",
      "('runLEFT(13).png'),pygame.image.load \n",
      "('runLEFT(14).png'),pygame.image.load \n",
      "('runLEFT(15).png'),pygame.image.load \n",
      "('runLEFT(16).png'),pygame.image.load \n",
      "('runLEFT(17).png'),pygame.image.load \n",
      "('runLEFT(18).png'),pygame.image.load \n",
      "('runLEFT(19).png'),pygame.image.load ('runLEFT(20).png')]\n",
      "\n",
      "bg = pygame.image.load ('bg.jpg')\n",
      "\n",
      "playerStand = [pygame.image.load ('Idle (1).png'),pygame.image.load \n",
      "('Idle (2).png'),pygame.image.load ('Idle (3).png'),pygame.image.load \n",
      "('Idle (4).png'),pygame.image.load ('Idle (5).png'),pygame.image.load \n",
      "('Idle (6).png'),pygame.image.load ('Idle (7).png'),pygame.image.load \n",
      "('Idle (8).png'),pygame.image.load ('Idle (9).png'),pygame.image.load \n",
      "('Idle (10).png'),pygame.image.load ('Idle (11).png'),pygame.image.load \n",
      "('Idle (12).png'),pygame.image.load ('Idle (13).png'),pygame.image.load \n",
      "('Idle (14).png'),pygame.image.load ('Idle (15).png'),pygame.image.load \n",
      "('Idle (16).png')]\n",
      "\n",
      "clock = pygame.time.Clock()\n",
      "\n",
      "x= 50\n",
      "y = 425\n",
      "width = 416\n",
      "hight = 454\n",
      "speed = 5\n",
      "\n",
      "isJump = False\n",
      "jumpCount = 10\n",
      "\n",
      "left = False\n",
      "right = False\n",
      "animCount = 0\n",
      "\n",
      "def drawWindow():\n",
      "    global animCount\n",
      "\n",
      "    if animCount + 1 >= 100:\n",
      "        animCount = 0\n",
      "\n",
      "    if left:\n",
      "        win.blit(runLeft[animCount // 5]), (x, y)\n",
      "        animCount += 1\n",
      "    elif right:\n",
      "        win.blit(runRight[animCount // 5]), (x, y)\n",
      "        animCount += 1\n",
      "    else:\n",
      "        win.blit(playerStand[animCount // 5]), (x, y)\n",
      "        animCount += 1\n",
      "\n",
      "    win.blit(bg, (0, 0))\n",
      "    pygame.display.update()\n",
      "\n",
      "run = True\n",
      "while run:\n",
      "    clock.tick(100)\n",
      "\n",
      "    for event in pygame.event.get():\n",
      "     if event.type == pygame.QUIT:\n",
      "        run = False\n",
      "\n",
      "    keys = pygame.key.get_pressed()\n",
      "    if keys[pygame.K_LEFT] and x > 5:\n",
      "        x -= speed\n",
      "        left = True\n",
      "        right = False\n",
      "    elif keys[pygame.K_RIGHT] and x < 500 - width - 5:\n",
      "        x += speed\n",
      "        left = False\n",
      "        right = True\n",
      "    else:\n",
      "        left = False\n",
      "        right = False\n",
      "        animCount = 0\n",
      "    if not(isJump):\n",
      "        if keys[pygame.K_UP] and y > 5:\n",
      "            y -= speed\n",
      "        if keys[pygame.K_DOWN] and y < 500 - hight - 15:\n",
      "            y += speed\n",
      "        if keys[pygame.K_SPACE]:\n",
      "            isJump = True\n",
      "    else:\n",
      "        if jumpCount >= -10:\n",
      "            if jumpCount < 0:\n",
      "                y += (jumpCount ** 2) / 2\n",
      "            else:\n",
      "                y -= (jumpCount ** 2) / 2\n",
      "            jumpCount -= 1\n",
      "        else:\n",
      "            isJump = False\n",
      "            jumpCount = 10\n",
      "\n",
      "    drawWindow()\n",
      "\n",
      "pygame.quit()\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071445/what-websites-provide-more-examples-to-clear-concepts-on-python\n",
      "What websites provide more examples to clear concepts on python?\n",
      "\n",
      "\n",
      "I found https://anandology.com to learn python. The best thing about this website is that it has small practice codes with the help of which the concepts get clear and they help to understand the logic behind what python is doing and why it is doing it.\n",
      "I have seen websites like\n",
      "codecademy.com\n",
      "khanacademy.org\n",
      "udacity.com\n",
      "w3schools.com\n",
      "code.org\n",
      "learncpp.com\n",
      "udemy.com\n",
      "coursera.org\n",
      "\n",
      "but I want some websites which have small codes, less description, more practice questions so that I can learn python(basics) faster. \n",
      "Why I am asking for what I am asking? \n",
      "There are many sites with good detailed descriptions. But my concepts are still not clear on small things. For eg how finally would always run even though there is an exception that has occurred. How MRO is expected to work(done with lots of practice)?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071436/how-to-override-flask-table-class\n",
      "How to override flask-table class\n",
      "\n",
      "\n",
      "I'm trying to override flask-table class to add some columns depending on options.\n",
      "Currently I'm generating route:\n",
      "@app.route(\"/delete_database\", methods=[\"GET\", \"POST\"])\n",
      "def delete_database():\n",
      "    table_content = Databases.query.all()\n",
      "    table2 = DatabasesTable(table_content)\n",
      "    # table2.add_column(col=LinkCol(\"Delete\", endpoint=\"index\"), name=\"witam\")\n",
      "    response = make_response(render_template(\"delete_database.html\", title=\"Delete database\", table=table2))\n",
      "    return response\n",
      "\n",
      "view:\n",
      "{% extends \"base.html\" %}\n",
      "{% block app_content %}\n",
      "\n",
      "        <div class=\"row\" style=\"padding:2%\">\n",
      "            {{ table }}\n",
      "        </div>\n",
      "\n",
      "{% endblock %}\n",
      "\n",
      "table class:\n",
      "    from flask_table import Table, Col, LinkCol,\n",
      "class DatabasesTable(Table):\n",
      "\n",
      "    def sort_url(self, col_id, reverse=False):\n",
      "        pass\n",
      "\n",
      "    classes = ['table table-hover']\n",
      "    table_id = \"databases_table\"\n",
      "    id = Col(\"Column name\")\n",
      "    name = Col(\"Column name\")\n",
      "    service = Col(\"Column name\")\n",
      "    description = Col(\"Column name\")\n",
      "    count = Col(\"Column name\")\n",
      "    timestamp = Col(\"Column name\")\n",
      "    some_db_table = Col(\"Column name\")\n",
      "    some_db_table2 = Col(\"Column name\")\n",
      "    some_db_table3 = Col(\"Column name\")\n",
      "    some_db_table4 = Col(\"Column name\")\n",
      "    more = LinkCol(\"Column name\")\n",
      "\n",
      "Everything works perfectly but I would like to add column Edit with delete buttons depending on route options (for example check if user is moderator and then add column with delete button).\n",
      "I have tried already:\n",
      "class DatabasesTable(Table):\n",
      "\n",
      "    def __init__(self, new_options=None):\n",
      "        self.new_options = new_options\n",
      "        super().__init__(self)\n",
      "\n",
      "    def sort_url(self, col_id, reverse=False):\n",
      "        pass\n",
      "\n",
      "    classes = ['table table-hover']\n",
      "    table_id = \"databases_table\"\n",
      "    id = Col(\"Column name\")\n",
      "    name = Col(\"Column name\")\n",
      "    service = Col(\"Column name\")\n",
      "    description = Col(\"Column name\")\n",
      "    count = Col(\"Column name\")\n",
      "    timestamp = Col(\"Column name\")\n",
      "    some_db_table = Col(\"Column name\")\n",
      "    some_db_table2 = Col(\"Column name\")\n",
      "    some_db_table3 = Col(\"Column name\")\n",
      "    some_db_table4 = Col(\"Column name\")\n",
      "    more = LinkCol(\"Column name\")\n",
      "    if options[\"edit\"]:\n",
      "        edit = Column_with_Delete_button\n",
      "\n",
      "but I have error:\n",
      "TypeError: 'DatabasesTable' object is not iterable\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071435/converting-perl-lwpuseragent-to-python-urllib3\n",
      "converting Perl LWP::UserAgent to python urllib3\n",
      "\n",
      "\n",
      "A script to authenticate to a Cisco Systems firewall needs to be converted from perl to Python.\n",
      "This perl script needs to be converted to a python equivalent.\n",
      "#!/usr/bin/perl\n",
      "\n",
      "$login=$ARGV[0];\n",
      "$pass=$ARGV[1];\n",
      "\n",
      "# load necessary perl modules\n",
      "use HTTP::Request::Common;\n",
      "use LWP::UserAgent;\n",
      "\n",
      "$url=\"https://<ip>/netaccess/loginuser.html\";\n",
      "\n",
      "my $ua = LWP::UserAgent->new(ssl_opts => { verify_hostname => 0 });\n",
      "\n",
      "# POST credentials\n",
      "\n",
      "my $res = $ua->request(POST \"$url\", [username => \"$login\", password => \"$pass\", sid => \"0\"]);\n",
      "$res->is_success or die \"Failed to POST credentials to '$url': \", $res->status_line;\n",
      "\n",
      "#!/bin/python\n",
      "import requests\n",
      "import urllib3\n",
      "import sys\n",
      "\n",
      "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
      "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
      "\n",
      "session = requests.Session()\n",
      "\n",
      "payload = {'sid' : '0', \"username\" : sys.argv[1], \"password\" : sys.argv[2]}\n",
      "\n",
      "r_post = session.post(\"https://9.134.79.20:950/netaccess/loginuser.html\",\n",
      "   data=payload,\n",
      "   verify=False,\n",
      "   )\n",
      "\n",
      "print(r_post.text)\n",
      "\n",
      "The result is actually not the same. I looks like pytong is sending this as a parameters in the URL, while with perl this is in the form.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071426/python-3-modules-user-configurable-relative-directories\n",
      "Python 3 modules: user configurable relative directories?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So I have a convention (perhaps it is a bad one) that I structure my python packages somewhat like this:\n",
      "<py-pkg>\n",
      "    __init__.py\n",
      "    settings.py\n",
      "    subpkg/\n",
      "        __init__.py\n",
      "        module.py\n",
      "    ...\n",
      "\n",
      "where in settings.py\n",
      "'''-----------------------------------------------------------------------------\n",
      "DIRECTORIES AND FILES\n",
      "-----------------------------------------------------------------------------'''\n",
      "MODULE_DIR      = os.path.dirname(os.path.realpath(__file__))\n",
      "PROJECT_DIR     = os.path.join(MODULE_DIR, '..')\n",
      "DATA_DIR        = os.path.join(PROJECT_DIR, 'data')\n",
      "SOURCE_DIR      = os.path.join(DATA_DIR, 'source')\n",
      "DERIVED_DIR     = os.path.join(DATA_DIR, 'derived')\n",
      "\n",
      "# other relevant relative paths to default files / paths\n",
      "\n",
      "While this works often quite well for me, it may be the case where say the user wants to update DATA_DIR and all dependent paths. \n",
      "How could I make that configurable?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071365/best-practice-to-create-flag-for-multiprocess-project-with-db-as-bridge-betwee\n",
      "Best practice to create “flag” for multiprocess project with db as bridge between processes?\n",
      "\n",
      "\n",
      "I have two processes: 1) scrapper - take info from another website, do the needfull calculations and put results in db 2) web app (Flask) take data from db and draw plot with the help of matpotlib. The two processes do not communicate, but they use one db.\n",
      "Problem: All works fine now, but to draw plots and save them to folder of web app project is time consuming operation, it takes about 5 seconds to display the page with plots. Pictures are created every time the webpage is requested, since data can be added to db in random moment and user should get plot with all information.\n",
      "How I see the solution: To create table in db with only one line and only two colums: id = 1 and  boolean field in db. Let's call boolean column IS_UPDATED. When the scrapper process put some new data to db, we change IS_UPDATED to True.  When the second process web app ask the data from db, it changes IS_UPDATED to False. Hereby the pictures are recreted only when new data was provided to db by the scrapper process, otherwise we use the old pictures.\n",
      "Is my solution is fine? Please share any other ways to do the same.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071345/sending-python-post-request-for-multiple-user\n",
      "Sending python post request for multiple user\n",
      "\n",
      "\n",
      "I want to prepare a python script which send post request for 1000 user at once and update them all as per api call.I already have curl. \n",
      "pyhton script \n",
      " import sys\n",
      " import uuid\n",
      " import json\n",
      " import requests\n",
      " import hashlib\n",
      " import time\n",
      " headers1 = {'X-Tenant-Key':'test1','X-Tenant-Name':'test','Content- \n",
      " Type': 'application/json','Cache-Control':'no-cache'}\n",
      " count=0\n",
      " for line in open(\"/home/pallav/postpaid_restart.txt\"):\n",
      "columns = line.rstrip('\\n').split('\\t')\n",
      "if(len(columns)==1):\n",
      "    uid=columns[0]\n",
      "\n",
      "    try:\n",
      "            url2='http://something..../postpaid/restart/'+uid\n",
      "\n",
      "            count=count+1\n",
      "            r3= requests.post(url2, headers=headers1)\n",
      "            print count,uid,r3.status_code\n",
      "            time.sleep(0.05)\n",
      "            if count%500==0:\n",
      "                    time.sleep(3)\n",
      "            if count%1000==0:\n",
      "                    time.sleep(3)\n",
      "    except:\n",
      "            time.sleep(0.03)\n",
      "            continue\n",
      "\n",
      "this is curl \n",
      "     curl -X POST \\\n",
      "     'http://something..../kyc/postpaid/restart?user_id=<USERID>' \\\n",
      "     -H 'Cache-Control: no-cache' \\\n",
      "     -H 'Content-Type: application/json' \\\n",
      "    -H 'X-TENANT-KEY: test1' \\\n",
      "     -H 'X-TENANT-NAME: test'\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071311/pdfreaderror-eof-marker-not-found-python-3\n",
      "PdfReadError: EOF marker not found (Python 3)\n",
      "\n",
      "\n",
      "I am downloading multiple PDFs. I have a list of urls and the code is written to download them and also create one big pdf with them all in. The code works for the first 144 pdfs then it throws this error: \n",
      "PdfReadError: EOF marker not found\n",
      "I've tried making all the pdfs end in %%EOF but that doesn't work - it still reaches the same point then I get the error again. \n",
      "Here's my code: \n",
      "my file and converting to list for python to read each separately\n",
      "with open('minutelinks.txt', 'r') as file:\n",
      "    data = file.read() \n",
      "links = data.split()\n",
      "\n",
      "download pdfs\n",
      "from PyPDF2 import PdfFileMerger\n",
      "import requests\n",
      "urls = links \n",
      "\n",
      "merger = PdfFileMerger()\n",
      "for url in urls:\n",
      "    response = requests.get(url)\n",
      "    title = url.split(\"/\")[-1]\n",
      "    with open(title, 'wb') as f:\n",
      "        f.write(response.content)\n",
      "        merger.append(title)\n",
      "\n",
      "merger.write(\"allminues.pdf\")\n",
      "merger.close()\n",
      "\n",
      "I want to be able to download all of them and create one big pdf - which it appears to do until it throws this error. I have about 750 pdfs and it only gets to 144.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071276/add-2-list-of-lists-with-different-lengths\n",
      "Add 2 list of lists with different lengths\n",
      "\n",
      "\n",
      "I have 2 lists.\n",
      "List 1 (say X) is = \n",
      "[ 0 , 0 , 0 , 0 ]\n",
      "\n",
      "List 2 is a list (Say Y) of list which will always have row size in multiples of 4 BUT the row sizes may not be same. \n",
      "eg - \n",
      "[[1,2,3,4,5,6,7,8] , [1,2,3,4]]\n",
      "\n",
      "I want to find column-wise sum of elements in groups of 4\n",
      "So for this example the sums will be [2,4,6,8] [5,6,7,8]\n",
      "Currently, I am using \n",
      "X = [sum(e) for e in zip(X , Y[j][count:count+4])]\n",
      "Where count is fixed for one complete traversal of columns. So say the number of columns in Y are 200. So for each traversal for groups of 4 numbers, count will stay same (it is used to slice the matrix)\n",
      "But as soon as the row length changes for the last 4 elements, X becomes empty.\n",
      "Where count is incremented as soon as Y gets fully traversed column-wise.\n",
      "Please ask for any further details. I can also provide a minimal reproducible example if needed in the form of a text file containing the matrix and the code I am currently using.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071261/lemmatization-package-for-dutch\n",
      "Lemmatization package for Dutch\n",
      "\n",
      "\n",
      "I'm looking for a package to do lemmatization in Dutch. Is there anything available?\n",
      "Azure Machine learning studio says, that it supports other language (incl. Dutch), but it doesn't work.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071254/how-to-send-an-image-or-bytes-array-from-image-in-a-json-from-client-to-backend\n",
      "how to send an Image or bytes array from Image in a JSON from Client to backend Server and then store it in Mongodb\n",
      "\n",
      "\n",
      "so I'm working on a Microservices Project, I'm using Python as a language and RabbitMQ as Message broker. I'm working on an App Store application and I'm facing this Problem that the frontend should send me some data in a JSON which include for example (name of the app -> str, title of the app -> str, image or images of the app -> image ....) and that will be sent as a Request over RabbitMQ, the backend should consume that Request and store those data in a Mongodb database and then return a Response for example {\"Success\": true}.   \n",
      "I ve tried so many things, I figured out how to store an Image in the Database. what I didnt figure out is how to send that Image data in a JSON. \n",
      "I tried base64 encoding, utf8, latin1 but None of it works because type bytes is not JSON serializable as the Error said. I searched a lot in the Internet but I didnt find exactly what I'm looking for although sometimes there is a similar questions but I tried almost everything and they didnt provide what I'm looking for.\n",
      "  data = {\n",
      "\"tool_owner\": \"John\",\n",
      "\"developer\": \"John\",\n",
      "\"icon\": # icon of the app,\n",
      " \"images\": # list of images,\n",
      "\"rating\": {\"user\": \"daniel\", \"date\": str(now), \"number\": 5},\n",
      "    }\n",
      "\n",
      "   d = json.dumps(data) # this is my goal. to send the data as a JSON\n",
      "   temp = json.loads(d) # and receive it in the backend and parse it so I \n",
      "     can retrieve the data and store it in mongodb \n",
      "\n",
      "in the First time, I face this Error: TypeError: Object of type bytes is not JSON serializable.\n",
      "I tried to look how can I convert bytes to strings so that I can send it in a JSON but what I found didnt work for me since I tried base64 encoding and latin1 encoding... \n",
      "I hope someone already faced this Problem and can help me with some Tips. Thank you all\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071248/removing-an-entire-row-with-conditions-on-a-column\n",
      "removing an entire row with conditions on a column\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following the question and solution posted here: How could I remove the rows of an array if one of the elements of the row does not satisfy a condition?\n",
      "I like to ask how to delete a row with a combined operator condition on a column value. In short, I like to delete all the rows whose 3rd column values are not between 7 and 15.\n",
      "print (data[:,2])\n",
      "to_remove = data[:,2] < 7 and  data[:,2] >= 15\n",
      "\n",
      "The above line is not allowed.\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "Answer\n",
      "\n",
      "Try:\n",
      "to_remove = (data[:,2] < 7) | (data[:,2] > 14)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071222/remove-connecting-areas-of-same-color-smaller-than-a-given-size-from-image\n",
      "Remove connecting areas of same color smaller than a given size from Image\n",
      "\n",
      "\n",
      "I have a fairly large (250000 x 250000 px) GeoTIFF containing black areas of interest on white background (white on black would also be possible). Due to I need my areas of interest as polygons in geojson format I run gdal_polygonize.py. Due to the large number of (small) black areas gdal_polygonize.py runs about a week on that large file. \n",
      "In a post-process step, I delete all polygons (in the geojson) which are to small to contain a rectangle with given dimensions, e.g. 10 x 100px. \n",
      "To reduce the workload for gdal_polygonize.py I'm looking for a way to get rid of those black areas in my geoTiff that are \"small\" befor running gdal_polygonize.py. \"Small\" could be defined e.g. as \"less than 1000 black pixel\".\n",
      "Anny idea to delete areas of the same color up to a given area size in an image?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071218/how-to-resolve-error-upgrading-scikit-learn\n",
      "How to resolve error upgrading scikit-learn\n",
      "\n",
      "\n",
      "I receive errors when trying to upgrade sci-kit learn. Please see code below.\n",
      "When checking the version of sci-kit in Python it tells me that 'sklearn has no attribute __version'. However, when checking on conda list it shows that sci-kit learn 0.20.3 is installed. not sure how to resolve the error below.\n",
      "(base) C:\\Users\\Marilyns.CORNASTONE>conda update scikit-learn\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "Package Plan\n",
      "  environment location: C:\\Users\\Marilyns.CORNASTONE\\AppData\\Local\\Continuum\\ana\n",
      "conda3\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  joblib             pkgs/main/win-64::joblib-0.13.2-py37_0\n",
      "  json5              pkgs/main/noarch::json5-0.8.4-py_0\n",
      "  mock               pkgs/main/win-64::mock-3.0.5-py37_0\n",
      "  sphinxcontrib-app~ pkgs/main/noarch::sphinxcontrib-applehelp-1.0.1-py_0\n",
      "  sphinxcontrib-dev~ pkgs/main/noarch::sphinxcontrib-devhelp-1.0.1-py_0\n",
      "  sphinxcontrib-htm~ pkgs/main/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0\n",
      "  sphinxcontrib-jsm~ pkgs/main/noarch::sphinxcontrib-jsmath-1.0.1-py_0\n",
      "  sphinxcontrib-qth~ pkgs/main/noarch::sphinxcontrib-qthelp-1.0.2-py_0\n",
      "  sphinxcontrib-ser~ pkgs/main/noarch::sphinxcontrib-serializinghtml-1.1.3-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  anaconda-project   pkgs/main/win-64::anaconda-project-0.~ --> pkgs/main/noarch\n",
      "::anaconda-project-0.8.3-py_0\n",
      "  astropy                              3.1.2-py37he774522_0 --> 3.2.1-py37he7745\n",
      "22_0\n",
      "  babel                pkgs/main/win-64::babel-2.6.0-py37_0 --> pkgs/main/noarch\n",
      "::babel-2.7.0-py_0\n",
      "  backports          pkgs/main/win-64::backports-1.0-py37_1 --> pkgs/main/noarch\n",
      "::backports-1.0-py_2\n",
      "  bitarray                             0.8.3-py37hfa6e2cd_0 --> 0.9.3-py37he7745\n",
      "22_0\n",
      "  blosc                                   1.15.0-h7bd577a_0 --> 1.16.3-h7bd577a_\n",
      "0\n",
      "  bokeh                                        1.0.4-py37_0 --> 1.2.0-py37_0\n",
      "  bzip2                                    1.0.6-hfa6e2cd_5 --> 1.0.8-he774522_0\n",
      "\n",
      "  cffi                                1.12.2-py37h7a1dbc1_1 --> 1.12.3-py37h7a1d\n",
      "bc1_0\n",
      "  cloudpickle        pkgs/main/win-64::cloudpickle-0.8.0-p~ --> pkgs/main/noarch\n",
      "::cloudpickle-1.2.1-py_0\n",
      "  cryptography                         2.6.1-py37h7a1dbc1_0 --> 2.7-py37h7a1dbc1\n",
      "_0\n",
      "  curl                                    7.64.0-h2a8f88b_2 --> 7.64.1-h2a8f88b_\n",
      "0\n",
      "  cython                              0.29.6-py37ha925a31_0 --> 0.29.12-py37ha92\n",
      "5a31_0\n",
      "  cytoolz                            0.9.0.1-py37hfa6e2cd_1 --> 0.10.0-py37he774\n",
      "522_0\n",
      "  dask                  pkgs/main/win-64::dask-1.1.4-py37_1 --> pkgs/main/noarch\n",
      "::dask-2.1.0-py_0\n",
      "  dask-core          pkgs/main/win-64::dask-core-1.1.4-py3~ --> pkgs/main/noarch\n",
      "::dask-core-2.1.0-py_0\n",
      "  defusedxml         pkgs/main/win-64::defusedxml-0.5.0-py~ --> pkgs/main/noarch\n",
      "::defusedxml-0.6.0-py_0\n",
      "  distributed        pkgs/main/win-64::distributed-1.26.0-~ --> pkgs/main/noarch\n",
      "::distributed-2.1.0-py_0\n",
      "  fastcache                            1.0.2-py37hfa6e2cd_2 --> 1.1.0-py37he7745\n",
      "22_0\n",
      "  filelock           pkgs/main/win-64::filelock-3.0.10-py3~ --> pkgs/main/noarch\n",
      "::filelock-3.0.12-py_0\n",
      "  flask                pkgs/main/win-64::flask-1.0.2-py37_1 --> pkgs/main/noarch\n",
      "::flask-1.1.1-py_0\n",
      "  glob2                  pkgs/main/win-64::glob2-0.6-py37_1 --> pkgs/main/noarch\n",
      "::glob2-0.7-py_0\n",
      "  importlib_metadata                             0.8-py37_0 --> 0.17-py37_1\n",
      "  intel-openmp                                   2019.3-203 --> 2019.4-245\n",
      "  ipykernel                            5.1.0-py37h39e3cac_0 --> 5.1.1-py37h39e3c\n",
      "ac_0\n",
      "  ipython                              7.4.0-py37h39e3cac_0 --> 7.6.1-py37h39e3c\n",
      "ac_0\n",
      "  ipywidgets         pkgs/main/win-64::ipywidgets-7.4.2-py~ --> pkgs/main/noarch\n",
      "::ipywidgets-7.5.0-py_0\n",
      "  isort                                       4.3.16-py37_0 --> 4.3.21-py37_0\n",
      "  jdcal                  pkgs/main/win-64::jdcal-1.4-py37_0 --> pkgs/main/noarch\n",
      "::jdcal-1.4.1-py_0\n",
      "  jinja2                                        2.10-py37_0 --> 2.10.1-py37_0\n",
      "  jupyter_client     pkgs/main/win-64::jupyter_client-5.2.~ --> pkgs/main/noarch\n",
      "::jupyter_client-5.3.1-py_0\n",
      "  jupyter_core       pkgs/main/win-64::jupyter_core-4.4.0-~ --> pkgs/main/noarch\n",
      "::jupyter_core-4.5.0-py_0\n",
      "  jupyterlab                          0.35.4-py37hf63ae98_0 --> 1.0.2-py37hf63ae\n",
      "98_0\n",
      "  jupyterlab_server  pkgs/main/win-64::jupyterlab_server-0~ --> pkgs/main/noarch\n",
      "::jupyterlab_server-1.0.0-py_0\n",
      "  kiwisolver                           1.0.1-py37h6538335_0 --> 1.1.0-py37ha925a\n",
      "31_0\n",
      "  lazy-object-proxy                    1.3.1-py37hfa6e2cd_2 --> 1.4.1-py37he7745\n",
      "22_0\n",
      "  libcurl                                 7.64.0-h2a8f88b_2 --> 7.64.1-h2a8f88b_\n",
      "0\n",
      "  libpng                                  1.6.36-h2a8f88b_0 --> 1.6.37-h2a8f88b_\n",
      "0\n",
      "  libssh2                                  1.8.0-h7a1dbc1_4 --> 1.8.2-h7a1dbc1_0\n",
      "\n",
      "  llvmlite                            0.28.0-py37ha925a31_0 --> 0.29.0-py37ha925\n",
      "a31_0\n",
      "  lxml                                 4.3.2-py37h1350720_0 --> 4.3.4-py37h13507\n",
      "20_0\n",
      "  matplotlib                           3.0.3-py37hc8f65d3_0 --> 3.1.0-py37hc8f65\n",
      "d3_0\n",
      "  mkl                                            2019.3-203 --> 2019.4-245\n",
      "  mkl_fft                             1.0.10-py37h14836fe_0 --> 1.0.12-py37h1483\n",
      "6fe_0\n",
      "  more-itertools                               6.0.0-py37_0 --> 7.0.0-py37_0\n",
      "  nbconvert          pkgs/main/win-64::nbconvert-5.4.1-py3~ --> pkgs/main/noarch\n",
      "::nbconvert-5.5.0-py_0\n",
      "  networkx            pkgs/main/win-64::networkx-2.2-py37_1 --> pkgs/main/noarch\n",
      "::networkx-2.3-py_0\n",
      "  nltk                                           3.4-py37_1 --> 3.4.4-py37_0\n",
      "  numba                               0.43.1-py37hf9181ef_0 --> 0.44.1-py37hf918\n",
      "1ef_0\n",
      "  numpy                               1.16.2-py37h19fb1c0_0 --> 1.16.4-py37h19fb\n",
      "1c0_0\n",
      "  numpy-base                          1.16.2-py37hc3f5095_0 --> 1.16.4-py37hc3f5\n",
      "095_0\n",
      "  numpydoc           pkgs/main/win-64::numpydoc-0.8.0-py37~ --> pkgs/main/noarch\n",
      "::numpydoc-0.9.1-py_0\n",
      "  openpyxl           pkgs/main/win-64::openpyxl-2.6.1-py37~ --> pkgs/main/noarch\n",
      "::openpyxl-2.6.2-py_0\n",
      "  parso                pkgs/main/win-64::parso-0.3.4-py37_0 --> pkgs/main/noarch\n",
      "::parso-0.5.0-py_0\n",
      "  partd               pkgs/main/win-64::partd-0.3.10-py37_1 --> pkgs/main/noarch\n",
      "::partd-1.0.0-py_0\n",
      "  path.py            pkgs/main/win-64::path.py-11.5.0-py37~ --> pkgs/main/noarch\n",
      "::path.py-12.0.1-py_0\n",
      "  pathlib2                                     2.3.3-py37_0 --> 2.3.4-py37_0\n",
      "  pillow                               5.4.1-py37hdc69c19_0 --> 6.1.0-py37hdc69c\n",
      "19_0\n",
      "  pip                                         19.0.3-py37_0 --> 19.1.1-py37_0\n",
      "  pluggy              pkgs/main/win-64::pluggy-0.9.0-py37_0 --> pkgs/main/noarch\n",
      "::pluggy-0.12.0-py_0\n",
      "  prometheus_client  pkgs/main/win-64::prometheus_client-0~ --> pkgs/main/noarch\n",
      "::prometheus_client-0.7.1-py_0\n",
      "  psutil                               5.6.1-py37he774522_0 --> 5.6.3-py37he7745\n",
      "22_0\n",
      "  pycurl                            7.43.0.2-py37h7a1dbc1_0 --> 7.43.0.3-py37h7a\n",
      "1dbc1_0\n",
      "  pygments           pkgs/main/win-64::pygments-2.3.1-py37~ --> pkgs/main/noarch\n",
      "::pygments-2.4.2-py_0\n",
      "  pyparsing          pkgs/main/win-64::pyparsing-2.3.1-py3~ --> pkgs/main/noarch\n",
      "::pyparsing-2.4.0-py_0\n",
      "  pysocks                                      1.6.8-py37_0 --> 1.7.0-py37_0\n",
      "  pytables                             3.5.1-py37h1da0976_0 --> 3.5.2-py37h1da09\n",
      "76_1\n",
      "  pytest                                       4.3.1-py37_0 --> 5.0.1-py37_0\n",
      "  python-libarchive~                             2.8-py37_6 --> 2.8-py37_10\n",
      "  pytz                 pkgs/main/win-64::pytz-2018.9-py37_0 --> pkgs/main/noarch\n",
      "::pytz-2019.1-py_0\n",
      "  pywavelets                           1.0.2-py37h8c2d366_0 --> 1.0.3-py37h8c2d3\n",
      "66_1\n",
      "  pyyaml                                 5.1-py37he774522_0 --> 5.1.1-py37he7745\n",
      "22_0\n",
      "  qtconsole          pkgs/main/win-64::qtconsole-4.4.3-py3~ --> pkgs/main/noarch\n",
      "::qtconsole-4.5.1-py_0\n",
      "  qtpy                  pkgs/main/win-64::qtpy-1.7.0-py37_1 --> pkgs/main/noarch\n",
      "::qtpy-1.8.0-py_0\n",
      "  requests                                    2.21.0-py37_0 --> 2.22.0-py37_0\n",
      "  rope                 pkgs/main/win-64::rope-0.12.0-py37_0 --> pkgs/main/noarch\n",
      "::rope-0.14.0-py_0\n",
      "  scikit-image                        0.14.2-py37ha925a31_0 --> 0.15.0-py37ha925\n",
      "a31_0\n",
      "  scikit-learn                        0.20.3-py37h343c172_0 --> 0.21.2-py37h6288\n",
      "b17_0\n",
      "  setuptools                                  40.8.0-py37_0 --> 41.0.1-py37_0\n",
      "  snowballstemmer    pkgs/main/win-64::snowballstemmer-1.2~ --> pkgs/main/noarch\n",
      "::snowballstemmer-1.9.0-py_0\n",
      "  sphinx              pkgs/main/win-64::sphinx-1.8.5-py37_0 --> pkgs/main/noarch\n",
      "::sphinx-2.1.2-py_0\n",
      "  sphinxcontrib-web~ pkgs/main/win-64::sphinxcontrib-websu~ --> pkgs/main/noarch\n",
      "::sphinxcontrib-websupport-1.1.2-py_0\n",
      "  spyder                                       3.3.3-py37_0 --> 3.3.6-py37_0\n",
      "  spyder-kernels                               0.4.2-py37_0 --> 0.5.1-py37_0\n",
      "  sqlalchemy                           1.3.1-py37he774522_0 --> 1.3.5-py37he7745\n",
      "22_0\n",
      "  sqlite                                  3.27.2-he774522_0 --> 3.29.0-he774522_\n",
      "0\n",
      "  statsmodels                          0.9.0-py37h452e1ab_0 --> 0.10.0-py37h8c2d\n",
      "366_0\n",
      "  sympy                                          1.3-py37_0 --> 1.4-py37_0\n",
      "  tblib                pkgs/main/win-64::tblib-1.3.2-py37_0 --> pkgs/main/noarch\n",
      "::tblib-1.4.0-py_0\n",
      "  terminado                                    0.8.1-py37_1 --> 0.8.2-py37_0\n",
      "  toolz                pkgs/main/win-64::toolz-0.9.0-py37_0 --> pkgs/main/noarch\n",
      "::toolz-0.10.0-py_0\n",
      "  tornado                              6.0.2-py37he774522_0 --> 6.0.3-py37he7745\n",
      "22_0\n",
      "  tqdm                 pkgs/main/win-64::tqdm-4.31.1-py37_1 --> pkgs/main/noarch\n",
      "::tqdm-4.32.1-py_0\n",
      "  urllib3                                     1.24.1-py37_0 --> 1.24.2-py37_0\n",
      "  vs2015_runtime                     14.15.26706-h3a45250_0 --> 14.15.26706-h3a4\n",
      "5250_4\n",
      "  werkzeug           pkgs/main/win-64::werkzeug-0.14.1-py3~ --> pkgs/main/noarch\n",
      "::werkzeug-0.15.4-py_0\n",
      "  wheel                                       0.33.1-py37_0 --> 0.33.4-py37_0\n",
      "  widgetsnbextension                           3.4.2-py37_0 --> 3.5.0-py37_0\n",
      "  wrapt                               1.11.1-py37he774522_0 --> 1.11.2-py37he774\n",
      "522_0\n",
      "  xlsxwriter         pkgs/main/win-64::xlsxwriter-1.1.5-py~ --> pkgs/main/noarch\n",
      "::xlsxwriter-1.1.8-py_0\n",
      "  xlwings                                     0.15.4-py37_0 --> 0.15.8-py37_0\n",
      "  zict                  pkgs/main/win-64::zict-0.1.4-py37_0 --> pkgs/main/noarch\n",
      "::zict-1.0.0-py_0\n",
      "  zipp                  pkgs/main/win-64::zipp-0.3.3-py37_1 --> pkgs/main/noarch\n",
      "::zipp-0.5.1-py_0\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? y\n",
      "\n",
      "**\n",
      "\n",
      "    Preparing transaction: done\n",
      "    Verifying transaction: failed\n",
      "    ClobberError: This transaction has incompatible packages due to a shared path.\n",
      "      packages: defaults::spyder-3.3.6-py37_0, defaults::spyder-3.3.6-py37_0\n",
      "      path: 'menu/spyder_shortcut.json'\n",
      "    CondaVerificationError: The package for scikit-learn located at C:\\Users\\Marilyn\n",
      "    s.CORNASTONE\\AppData\\Local\\Continuum\\anaconda3\\Anaconda3\\pkgs\\scikit-learn-0.21.\n",
      "    2-py37h6288b17_0\n",
      "    appears to be corrupted. The path 'Lib/site-packages/sklearn/datasets/tests/data\n",
      "    /openml/292/api-v1-json-data-list-data_name-australian-limit-2-data_version-1-st\n",
      "    atus-deactivated.json.gz'\n",
      "    specified in the package manifest cannot be found.\n",
      "    CondaVerificationError: The package for scikit-learn located at C:\\Users\\Marilyn\n",
      "    s.CORNASTONE\\AppData\\Local\\Continuum\\anaconda3\\Anaconda3\\pkgs\\scikit-learn-0.21.\n",
      "    2-py37h6288b17_0\n",
      "    appears to be corrupted. The path 'Lib/site-packages/sklearn/datasets/tests/data\n",
      "    /openml/40675/api-v1-json-data-list-data_name-glass2-limit-2-data_version-1-stat\n",
      "    us-deactivated.json.gz'\n",
      "    specified in the package manifest cannot be found.\n",
      "\n",
      "**\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071198/how-do-i-satisfy-these-conditions-in-my-loop-for-python\n",
      "How do I satisfy these conditions in my loop for Python\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to find the engagement rate for each data row and then find the video title with the highest engagement rate.\n",
      "Row in the dict youtube_usa_videos consist of many elements of which the index for each element has been named. The problem arises when I try to set the condition as seen below. \n",
      "Engagement rate = no. of comments / no. of views \n",
      "#code below\n",
      "\n",
      "highest_EGR = 0\n",
      "\n",
      "for row in youtube_usa_videos:\n",
      "\n",
      "    comments = row [8]\n",
      "    views = row [5]\n",
      "    title = row [1]\n",
      "\n",
      "    if views != 0:\n",
      "        EGR = comments / views\n",
      "    else:\n",
      "        EGR = 0\n",
      "\n",
      "    If EGR > highest_EGR:\n",
      "        highest_EGR = EGR\n",
      "        top_vid = title \n",
      "\n",
      "Can you help me clean my code such that the conditions will be met and the top video title and its engagement rate will be printed?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071181/getting-ssl-error-sslcertverificationerror-certificate-verify-failed-unable-to\n",
      "Getting SSL Error: SSLCertVerificationError certificate verify failed: unable to get local issuer certificate\n",
      "\n",
      "\n",
      "I am hitting the SOAP WDSL Url, that URL is having certificate validation.\n",
      "I am having the generated pem certificate with me.\n",
      "So in the project, I created one folder and kept that certificate inside that like below:\n",
      "/path/cert.pem\n",
      "I am calling the WDSL URL using requests module in python. \n",
      "import requests \n",
      "capath = \"/path/cert.pem\"\n",
      "\n",
      "response = requests.post(URL, data=XMLBody, headers=Headers, verify=capath)\n",
      "\n",
      "But I am getting the below exception :\n",
      "HTTPSConnectionPool(host='URL', port=8443): Max retries exceeded with url:  (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)')))\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071151/cannot-post-a-zip-file-in-python-unicode-decoding-error\n",
      "Cannot post a zip file in Python. Unicode decoding error\n",
      "\n",
      "\n",
      "When trying to submit a zip file using urllib2 I am getting a UnicodeDecodeError with the following messages:\n",
      "Exception during urlopen: 'ascii' codec can't decode byte 0xf1 in position 12: ordinal not in range(128)\n",
      "Exception: 'ascii' codec can't decode byte 0xf1 in position 12: ordinal not in range(128)\n",
      "Exception of type: <type 'exceptions.UnicodeDecodeError'>\n",
      "Exception. Message: \"\". Doc: \"Unicode decoding error.\".\n",
      "Exception during export: \n",
      "e.__doc__=Unicode decoding error.\n",
      "\n",
      "The exception is raised on the line response = urllib2.urlopen(request).\n",
      "    def depositZipFile(tempZipFileName, tempZipFilePath, depositUrl, tr):\n",
      "        print('depositZipFile(). tempZipFileName=%s, tempZipFilePath=%s, depositUrl=%s, tr=%s' % (tempZipFileName, tempZipFilePath, depositUrl, str(tr)))\n",
      "        with open(tempZipFilePath, 'rb') as f:\n",
      "            zipData = f.read()\n",
      "            print('depositZipFile(). type(zipData)=%s' % type(zipData))\n",
      "\n",
      "            headers = {\n",
      "                'In-Progress': 'true',\n",
      "                'Content-Disposition': 'filename=' + tempZipFileName,\n",
      "                'Content-Type': 'application/zip',\n",
      "                'Content-Length': os.stat(tempZipFilePath).st_size,\n",
      "                'Content-Transfer-Encoding': 'binary',\n",
      "                'Packaging': 'http://purl.org/net/sword/package/METSDSpaceSIP',\n",
      "            }\n",
      "\n",
      "            try:\n",
      "                request = urllib2.Request(depositUrl, data=zipData, headers=headers)\n",
      "\n",
      "                try:\n",
      "                    response = urllib2.urlopen(request)\n",
      "                except Exception as e:\n",
      "                    print('Exception during urlopen: ' + str(e))\n",
      "                    raise e\n",
      "\n",
      "                print('Got response. response=%s' % str(response))\n",
      "\n",
      "                xmlText = response.read()\n",
      "                xmlRoot = ET.fromstring(xmlText)\n",
      "                linkElement = xmlRoot.find('xmlns:link[@rel=\"alternate\"]', namespaces=dict(xmlns='http://www.w3.org/2005/Atom'))\n",
      "\n",
      "                if linkElement is None:\n",
      "                    raise ValueError('No redirection URL is found in the response.')\n",
      "\n",
      "                href = linkElement.attrib['href']\n",
      "                return href\n",
      "            except urllib2.HTTPError as e:\n",
      "                print('HTTPError: ' + str(e))\n",
      "                print('HTTPError: %s' % str(e.code))\n",
      "                print('HTTPError message: %s' % e.read())\n",
      "                raise e\n",
      "            except Exception as e:\n",
      "                print('Exception: ' + str(e))\n",
      "                print('Exception of type: %s' % type(e))\n",
      "                print('Exception. Message: \"%s\". Doc: \"%s\".' % (e.message, e.__doc__))\n",
      "                raise e\n",
      "\n",
      "Before the aforementioned method is called the user is authenticated using basic authentication. See the following method.\n",
      "    def authenticateUser(tr, url):\n",
      "        user = getConfigurationProperty(tr, 'user')\n",
      "        password = getConfigurationProperty(tr, 'password')\n",
      "        realm = getConfigurationProperty(tr, 'realm')\n",
      "        pm = urllib2.HTTPPasswordMgr()\n",
      "        pm.add_password(realm, url, user, password)\n",
      "        authHandler = urllib2.HTTPBasicAuthHandler(pm)\n",
      "        opener = urllib2.build_opener(authHandler)\n",
      "        urllib2.install_opener(opener)\n",
      "\n",
      "I am very new to Python and maybe I am missing something obvious. Please advise.\n",
      "I am using Python 2.7, Jython implementation.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071146/want-to-convert-list-of-dictionaries-into-columns-of-list-in-python\n",
      "Want to convert list of dictionaries into columns of list in python\n",
      "\n",
      "\n",
      "I have a list of dictionaries lst having same two keys each having differnt values in every dictionaries. I want them in form of single dictionary dict\n",
      "where both keys has all its values into a list. Keeping in mind, keys are to be taken from variables dimLst and metricLst and they are unknown otherwise.. Any idea!!   \n",
      "lst = [\n",
      "    {'Location': 'ANNEX', 'ToTal_Dwell': 60.0},\n",
      "    {'Location': 'CHENNAI', 'ToTal_Dwell': 86.0},\n",
      "    {'Location': 'DADRI', 'ToTal_Dwell': 108.0},\n",
      "    {'Location': 'JNPT', 'ToTal_Dwell': 39.0},\n",
      "    {'Location': 'KOLKATA', 'ToTal_Dwell': 67.0},\n",
      "    {'Location': 'MUNDRA', 'ToTal_Dwell': 82.0}\n",
      "]\n",
      "\n",
      "dimLst = ['Location']\n",
      "metricsLst = ['ToTal_Dwell']\n",
      "\n",
      "i am expecting output to be like: \n",
      "dict = {\n",
      "    'Location': \n",
      "        ['ANNEX', 'CHENNAI', 'DADRI', 'JNPT', 'KOLKATA', 'MUNDRA'],\n",
      "    'ToTal_Dwell': \n",
      "        [60.0, 86.0, 108.0, 39.0, 67.0, 82.0]\n",
      "}\n",
      "\n",
      "Answer\n",
      "\n",
      "Use a dictionary comprehension:\n",
      ">>> {k: [d[k] for d in lst] for k in lst[0]}\n",
      "{'Location': ['ANNEX', 'CHENNAI', 'DADRI', 'JNPT', 'KOLKATA', 'MUNDRA'], 'ToTal_Dwell': [60.0, 86.0, 108.0, 39.0, 67.0, 82.0]}\n",
      "This is another solution besides dictionary comprehension\n",
      "lst = [\n",
      "    {'Location': 'ANNEX', 'ToTal_Dwell': 60.0},\n",
      "    {'Location': 'CHENNAI', 'ToTal_Dwell': 86.0},\n",
      "    {'Location': 'DADRI', 'ToTal_Dwell': 108.0},\n",
      "    {'Location': 'JNPT', 'ToTal_Dwell': 39.0},\n",
      "    {'Location': 'KOLKATA', 'ToTal_Dwell': 67.0},\n",
      "    {'Location': 'MUNDRA', 'ToTal_Dwell': 82.0}\n",
      "]\n",
      "\n",
      "locationList = []\n",
      "dwellList = []\n",
      "locDict = {}\n",
      "\n",
      "for i in lst:\n",
      "    locationList.append(i['Location'])\n",
      "    dwellList.append(i['ToTal_Dwell'])\n",
      "\n",
      "locDict['Location'] = locationList\n",
      "locDict['ToTal_Dwell'] = dwellList\n",
      "print(locDict)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071137/issue-when-drawing-a-numpy-array-into-a-qwidget\n",
      "Issue when drawing a numpy array into a QWidget\n",
      "\n",
      "\n",
      "I'm trying to code a preview widget that is able to display a 2D numpy array image.\n",
      "This widget has a fixed size (square), but the image can have any shape.\n",
      "It seems to work for some image shapes, but for other shapes it displays non-sense, and for some other shapes it crashes without any error message.\n",
      "Do you see an obvious mistake in my code?\n",
      "from silx.gui import qt\n",
      "import numpy\n",
      "\n",
      "\n",
      "GRAY_COLORTABLE = []\n",
      "for i in range(256):\n",
      "    GRAY_COLORTABLE.append(qt.qRgb(i, i, i))\n",
      "\n",
      "\n",
      "class PreviewImageWidget(qt.QWidget):\n",
      "    \"\"\"Preview image\"\"\"\n",
      "    def __init__(self, parent=None):\n",
      "        super().__init__(parent)\n",
      "        self.pixmap = qt.QPixmap()\n",
      "        self.setFixedSize(350, 350)\n",
      "\n",
      "    def paintEvent(self, event):\n",
      "        painter = qt.QPainter(self)\n",
      "        painter.drawPixmap(self.rect(), self.pixmap)\n",
      "\n",
      "    def setImage(self, img_array):\n",
      "        # TODO : adjust colortable to actual dtype (autoscale to min - max ??)\n",
      "        if img_array is None:\n",
      "            self.pixmap = qt.QPixmap()\n",
      "        else:\n",
      "            if img_array.dtype != numpy.uint8:\n",
      "                max_value = img_array.max()\n",
      "                img_array = 256. / max_value * img_array\n",
      "                img_array = img_array.astype(numpy.uint8)\n",
      "\n",
      "            # binary images are of dtype uint8\n",
      "            if img_array.max() == 1:\n",
      "                img_array = img_array * 255\n",
      "            image = qt.QImage(img_array,\n",
      "                              img_array.shape[1], img_array.shape[0],\n",
      "                              qt.QImage.Format_Indexed8)\n",
      "            image.setColorTable(GRAY_COLORTABLE)\n",
      "            self.pixmap = qt.QPixmap.fromImage(image)\n",
      "\n",
      "        self.update()\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    app = qt.QApplication([])\n",
      "    allPreviewWidgets = []\n",
      "\n",
      "    for sh in [(610, 500), (450, 700), (550, 600),\n",
      "               (500, 500), (510, 500), (500, 520)]:\n",
      "        img_array = numpy.zeros(sh, dtype=numpy.uint8)\n",
      "        img_array[200:350, 250:300] = 1\n",
      "\n",
      "        previewWidget = PreviewImageWidget()\n",
      "        previewWidget.setWindowTitle(str(img_array.shape))\n",
      "        previewWidget.show()\n",
      "        previewWidget.setImage(img_array)\n",
      "        allPreviewWidgets.append(previewWidget)\n",
      "\n",
      "    app.exec_()\n",
      "\n",
      "\n",
      "The shapes that are almost square don't work. The rectangle ones work fine.\n",
      "In the documentation of QPainter, it says: \n",
      "\n",
      "Note: The image is scaled to fit the rectangle, if both the image and\n",
      "  rectangle size disagree.\n",
      "\n",
      "An example of shape that makes the program crash: (2000, 500)\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071129/schedule-a-job-according-to-business-calendar\n",
      "Schedule a job according to business calendar\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to schedule a job on the 4th business day of every month according to the french calendar using schedule and workalender modules.\n",
      "Is there a simple way to do this? like combine business days with schedule?\n",
      "The solution I have so far is to schedule the job every month using schedule and then every day use workalendar to count the business days, at count 4 I run job but it's not very efficient in my opinion\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071074/how-to-use-django-and-database\n",
      "How to use django and database? [on hold]\n",
      "\n",
      "\n",
      "I'm supposed to use Django, Rest API and some database management type. Can somebody explain me that how to use these tools together?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071068/loop-to-label-multiple-axes\n",
      "loop to label multiple axes\n",
      "\n",
      "\n",
      "I need to run a loop to label 76 axes in a facetgrid plot I am creating. I am labelling the axes in a recurrent way -  after each 6 axes, I will start again from the label \"Overall Score\". If I were to do it manually, it would be like this:\n",
      "axes[0].set_title(\"Overall Score\")\n",
      "axes[1].set_title(\"Business Ethics\")\n",
      "axes[2].set_title(\"Environment\")\n",
      "axes[3].set_title(\"Health & Safety\")\n",
      "axes[4].set_title(\"Labour\")\n",
      "axes[5].set_title(\"Management System\")\n",
      "axes[6].set_title(\"Overall Score\")\n",
      "....\n",
      "axes[75].set_title(\"Management System\")\n",
      "\n",
      "But I do not have patience and I want to run a loop. So far I developed this but I cannot proceed.\n",
      "for i in range(0,77):\n",
      "    if i == 1:\n",
      "       axes[i].set_title(\"Overall Score\") \n",
      "\n",
      "Suggestions?\n",
      "\n",
      "Answer\n",
      "\n",
      "Create list of all values by multiple by 13 and set in loop with enumerate for counter:\n",
      "vals = [\"Overall Score\",\"Business Ethics\",\"Environment\",\n",
      "        \"Health & Safety\",\"Labour\",\"Management System\"] * 13\n",
      "for i, v in enumerate(vals):\n",
      "    axes[i].set_title(v) \n",
      "\n",
      "Test:\n",
      "for i, v in enumerate(vals):\n",
      "    print (i, v)\n",
      "0 Overall Score\n",
      "1 Business Ethics\n",
      "2 Environment\n",
      "3 Health & Safety\n",
      "4 Labour\n",
      "5 Management System\n",
      "6 Overall Score\n",
      "...\n",
      "titles = (\n",
      "    \"Overall Score\", \"Business Ethics\", \"Environment\",\n",
      "    \"Health & Safety\", \"Labour\", \"Management System\"\n",
      ")\n",
      "num_of_axes = 76\n",
      "for i in range(num_of_axes):\n",
      "    axes[i].set_title(titles[i % len(titles)])\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071057/python-print-to-file-function-is-not-printing-to-file\n",
      "Python print to file function is not printing to file\n",
      "\n",
      "\n",
      "I am using the print function with output to file argument. The print function is under an if statement. Below is the code\n",
      "log_file = open(\"Src_files.log\", 'w') \n",
      "if count_1.equals(count_2) == False:\n",
      "    print('Error: Discrepancy with processed file. Count of records does not match with sources file', file=log_file) \n",
      "\n",
      "Count_1 and count_2 are unequal dataframes\n",
      "The code gets executed without throwing any error but when I check the log file, it does not contain the printed statement.\n",
      "How do I correct the code?\n",
      "\n",
      "Answer\n",
      "\n",
      "print does not flush by default. check the python manual to find that there is a flush keyword arg, or simply close the file. log_file.close()\n",
      "with open('Src_files.log', 'a') as log_file:\n",
      "    if count_1.equals(count_2) == False:\n",
      "        log_file.write('Error: Discrepancy with processed file. Count of records does not match with sources file')+\"\\n\")\n",
      "\n",
      "\n",
      "NOTE: With the \"With\" statement, you get better syntax and exceptions handling. The with statement simplifies exception handling by encapsulating common\n",
      "  preparation and cleanup tasks.\n",
      "  In addition, it will automatically close the file. The with statement provides\n",
      "  a way for ensuring that a clean-up is always used.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071035/compare-the-example-of-pytorch-and-keras-on-cifar10-data\n",
      "Compare the example of Pytorch and Keras on Cifar10 data\n",
      "\n",
      "\n",
      "I use Cifar10 data to learn how to coding on keras and pytorch.\n",
      "The environment is Python 3.6.7, Torch 1.0.0, Keras 2.2.4, Tensorflow 1.14.0.\n",
      "I use the same batch, epoch, learning rate, optimizer.\n",
      "I use DenseNet121 to be model.\n",
      "After training, keras get 0.69% accuracy in test data.\n",
      "Pytorch just get 0.54% in test data.\n",
      "I know the results are different, but why result very bad in pytorch, look like not learning?\n",
      "\n",
      "\n",
      "Here is Keras code:\n",
      "import os, keras\n",
      "from keras.datasets import cifar10\n",
      "from keras.applications.densenet import DenseNet121\n",
      "batch_size = 32\n",
      "num_classes = 10\n",
      "epochs = 20\n",
      "# The data, split between train and test sets:\n",
      "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
      "print('x_train shape:', x_train.shape)\n",
      "print(x_train.shape[0], 'train samples')\n",
      "print(x_test.shape[0], 'test samples')\n",
      "\n",
      "# Convert class vectors to binary class matrices.\n",
      "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
      "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
      "\n",
      "# model\n",
      "model = DenseNet121(include_top=True, weights=None, input_shape=(32,32,3), classes=10)\n",
      "\n",
      "# initiate RMSprop optimizer\n",
      "opt = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
      "\n",
      "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
      "\n",
      "x_train = x_train.astype('float32')\n",
      "x_test = x_test.astype('float32')\n",
      "x_train /= 255\n",
      "x_test /= 255\n",
      "\n",
      "model.fit(x_train, y_train,\n",
      "          batch_size=batch_size,\n",
      "          epochs=epochs,\n",
      "          validation_data=(x_test, y_test),\n",
      "          shuffle=True)\n",
      "\n",
      "# Score trained model.\n",
      "scores = model.evaluate(x_test, y_test, verbose=1)\n",
      "print('Test loss:', scores[0])\n",
      "print('Test accuracy:', scores[1])\n",
      "\n",
      "Here is Pytorch code:\n",
      "import torch\n",
      "import torchvision\n",
      "import torchvision.transforms as transforms\n",
      "from torch import flatten\n",
      "import torch.optim as optim\n",
      "from torchvision import transforms, models\n",
      "from torch.nn import Linear, Softmax, Module, Sequential, CrossEntropyLoss\n",
      "import numpy as np\n",
      "from tqdm import tqdm\n",
      "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
      "transform = transforms.Compose([transforms.ToTensor()])\n",
      "\n",
      "trainset = torchvision.datasets.CIFAR10(root='./DataSet', train=True, download=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)\n",
      "\n",
      "testset = torchvision.datasets.CIFAR10(root='./DataSet', train=False, download=True, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=0)\n",
      "\n",
      "\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "\n",
      "class Net(Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        self.funFeatExtra   = Sequential(*[i for i in list(models.densenet121().children())[:-1]])\n",
      "        self.funFlatten     = flatten\n",
      "        self.funOutputLayer = Linear(1024, 10)\n",
      "        self.funSoftmax     = Softmax(dim=1)\n",
      "    def forward(self, x):\n",
      "        x = self.funFeatExtra(x)\n",
      "        x = self.funFlatten(x, 1)\n",
      "        x = self.funOutputLayer(x)\n",
      "        x = self.funSoftmax(x)\n",
      "        return x\n",
      "\n",
      "\n",
      "net = Net()\n",
      "\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
      "\n",
      "for epoch in range(20):  # loop over the dataset multiple times\n",
      "\n",
      "    running_loss = 0.0\n",
      "    for i, data in tqdm(enumerate(trainloader, 0)):\n",
      "        # get the inputs; data is a list of [inputs, labels]\n",
      "        inputs, labels = data\n",
      "\n",
      "        # zero the parameter gradients\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        # forward + backward + optimize\n",
      "        outputs = net.cuda()(inputs.cuda())\n",
      "        loss = criterion(outputs, labels.cuda())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "\n",
      "        # print statistics\n",
      "        running_loss += loss.item()\n",
      "\n",
      "        # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
      "        #     print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
      "        #     running_loss = 0.0\n",
      "\n",
      "print('Finished Training')\n",
      "\n",
      "\n",
      "########################################################################\n",
      "# The results seem pretty good.\n",
      "#\n",
      "# Let us look at how the network performs on the whole dataset.\n",
      "\n",
      "correct = 0\n",
      "total = 0\n",
      "with torch.no_grad():\n",
      "    for data in tqdm(testloader):\n",
      "        images, labels = data\n",
      "        outputs = net.cpu()(images.cpu())\n",
      "        _, predicted = torch.max(outputs.data, 1)\n",
      "        total += labels.size(0)\n",
      "        correct += (predicted == labels).sum().item()\n",
      "\n",
      "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071027/flask-admin-remember-form-value\n",
      "Flask admin remember form value\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my application, I have Users and Posts as models. Each post has a foreign key to a username. When I create a ModelView on top of my Posts model I can create posts as specific users in the admin interface \n",
      "as seen in the screenshot below\n",
      "\n",
      "After I have added a post and click \"Save and Add Another\", the \"User\" reverts back to \"user1\". How can I make the form remember the previous value \"user2\"? \n",
      "My reserach has led me to believe it can be done by modifying on_model_change and on_form_prefill, and saving the previous value in the flask session, but it seems to be overengineering such a simple task. There must be a simpler way.\n",
      "My code can be seen below\n",
      "from flask import Flask\n",
      "from flask_sqlalchemy import SQLAlchemy\n",
      "import flask_admin\n",
      "from flask_admin.contrib import sqla\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "db = SQLAlchemy()\n",
      "\n",
      "admin = flask_admin.Admin(name='Test')\n",
      "\n",
      "\n",
      "class Users(db.Model):\n",
      "    \"\"\"\n",
      "    Contains users of the database\n",
      "    \"\"\"\n",
      "    user_id = db.Column(db.Integer, primary_key=True)\n",
      "    username = db.Column(db.String(64), index=True, unique=True, nullable=False)\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.username\n",
      "\n",
      "\n",
      "class Posts(db.Model):\n",
      "    \"\"\"\n",
      "    Contains users of the database\n",
      "    \"\"\"\n",
      "    post_id = db.Column(db.Integer, primary_key=True)\n",
      "    username = db.Column(db.String(11), db.ForeignKey(Users.username), nullable=False)\n",
      "    post = db.Column(db.String(256))\n",
      "    user = db.relation(Users, backref='user')\n",
      "\n",
      "\n",
      "def build_sample_db():\n",
      "    db.drop_all()\n",
      "    db.create_all()\n",
      "    data = {'user1': 'post1', 'user1': 'post2', 'user2': 'post1'}\n",
      "    for user, post in data.items():\n",
      "\n",
      "        u = Users(username=user)\n",
      "        p = Posts(username=user, post=post)\n",
      "\n",
      "        db.session.add(u)\n",
      "        db.session.add(p)\n",
      "    db.session.commit()\n",
      "\n",
      "class MyModelView(sqla.ModelView):\n",
      "\n",
      "    pass\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    app.config['SECRET_KEY'] = '123456790'\n",
      "    app.config['DATABASE_FILE'] = 'sample_db.sqlite'\n",
      "    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///database'\n",
      "    app.config['SQLALCHEMY_ECHO'] = True\n",
      "    db.init_app(app)\n",
      "\n",
      "    admin.init_app(app)\n",
      "    admin.add_view(MyModelView(Posts, db.session))\n",
      "\n",
      "    with app.app_context():\n",
      "        build_sample_db()\n",
      "\n",
      "    # Start app\n",
      "    app.run(debug=True)\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071014/i-have-problem-with-numpy-slices-when-using-scatter-plot-for-showing-all-data-h\n",
      "I have problem with numpy slices when using scatter plot for showing all data. How can i fix it?\n",
      "\n",
      "\n",
      "I have NumPy array which data.shape showing (485,4) and i can`t plotting it with plt.scatter \n",
      "array([[     20,       1,     263,  716693],\n",
      "       [     74,      51,     107,  274393],\n",
      "       [     27,       1,     165,  723841],...])\n",
      "\n",
      "plt.scatter(data[:0],data[:,1],c=data[0:],cmap='rainbow')\n",
      "\n",
      "I cant understand how can i slice it? I`m newbie can you help with plot it?\n",
      "\n",
      "Answer\n",
      "\n",
      "If you are trying to slice columns from numpy array. Here is the method. Hope it helps.\n",
      "import numpy\n",
      "from numpy import *\n",
      "test = numpy.array([[1, 2], [3, 4], [5, 6]])\n",
      "print( test[:,0])\n",
      "\n",
      "Output\n",
      "[1 3 5]\n",
      "\n",
      "Here it accesses the first column. You can replace 0 with 1 and 2 to access the next column numbers.\n",
      "If you want to access rows, here is the slicing method\n",
      "print( test[0,:])\n",
      "\n",
      "Output\n",
      "[3 4]\n",
      "\n",
      "It access first row of array.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57071002/pytorch-tensor-indexing\n",
      "Pytorch tensor indexing\n",
      "\n",
      "\n",
      "I am currently working on converting some code from tensorflow to pytorch, I encountered problem with tf.gather func, there is no direct function to convert it in pytorch.\n",
      "What I am trying to do is basically indexing, I have two tensors, feature tensor shapes of [minibatch, 60, 2] and indexing tensor [minibatch, 8], say like first tensor is tensor A, and the second one is B\n",
      "In Tensorflow, it is directly converted with tf.gather(A, B, batch_dims=1)\n",
      "How do I achieve this in pytorch?\n",
      "I have tried A[B] indexing. This seems not work\n",
      "and A[0]B[0] works, but output of shape is [8, 2]\n",
      "I need the shape of [minibatch, 8, 2]\n",
      "It will probably work if I stack tensor like [stack, 8, 2] but I have no idea how to do it\n",
      "tensorflow\n",
      "out = tf.gather(logits, indices, batch_dims=1)\n",
      "\n",
      "pytorch\n",
      "out = A[B] -> something like this will be great\n",
      "\n",
      "Output shape of [minibatch, 8, 2]\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070977/i-want-to-remove-noise-from-my-data-set-on-the-basis-of-a-base-data\n",
      "I want to remove noise from my data set on the basis of a base data\n",
      "\n",
      "\n",
      "I have performance data for 30 different businesses that I want to run the time series on separately, to identify seasonal trends.\n",
      "Problem - There are internal problems at the data collection source for some months which is affecting all the businesses majorly together.\n",
      "Objective - I want to take a business which is non-seasonal and take it as a base(i.e. it will only have disturbances from the internal problems and no other seasonal trend), and on the basis of this remove the noise from the other businesses so that the analysis would make more sense.\n",
      "I have tried using smoothers such as EWMA, SMA, Kaplan smoother, but the smoothening does not remove the noise but averages it out leading to biased predictions.\n",
      "I want my data to be removed of the noise created by the problem at the data collection side.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070878/how-to-access-specific-tag-inside-xml-with-elemntree\n",
      "How to access specific tag inside xml with elemntree?\n",
      "\n",
      "\n",
      "I'm trying to parse XML of tasks that includes dependencies and parameters tags, i want to iterate over the task and get the task name, params, depends.\n",
      "How would you recommend doing it? \n",
      "I tried to get task by task and get all the data needed by accessing the specific tag.\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<job xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:proactive:jobdescriptor:3.2\" xsi:schemaLocation=\"urn:proactive:jobdescriptor:3.2 http://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.2/schedulerjob.xsd\" name=\"Extra_02_StartFramegrabbers\" projectName=\"Extra_02_StartFramegrabbers\">\n",
      "  <description>Extra_02_StartFramegrabbers</description>\n",
      "  <taskFlow>\n",
      "    <task name=\"PrepGrabbersEnv\">\n",
      "      <depends>\n",
      "        <task ref=\"NothingAfterKill\"/>\n",
      "      </depends>\n",
      "      <javaExecutable class=\"exe\">\n",
      "        <parameters>\n",
      "          <parameter name=\"command\" value=\"C:\\ReplayCode\\Apps\\PrepareEnvironment\\PrepareEnvironment.exe\"/>\n",
      "          <parameter name=\"arguments\" value=\"C:\\ReplayCode\\INIFiles\\Static\\PrepGrabbersEnv.INI\"/>\n",
      "          <parameter name=\"computers\" value=\"AllComputers\"/>\n",
      "        </parameters>\n",
      "      </javaExecutable>\n",
      "      <controlFlow block=\"none\"/>\n",
      "    </task>\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070870/clear-datapoints-from-bokeh-plot\n",
      "clear datapoints from bokeh plot\n",
      "\n",
      "\n",
      "I'm still somewhat new to Bokeh, and I've run into a problem I haven't been able to solve. \n",
      "I have a Bokeh plot visualizing some streaming data in two separate figures. For various reasons the users of the plot may want to clear the two plots of the current datapoints upon clicking a button. \n",
      "What would be the good way to clear the figures? I am yet to come upon a good solution.\n",
      "My code looks something like:\n",
      "#Defining plots\n",
      "plot_data = ColumnDataSource(dict(x=[],y=[],z=[]))\n",
      "\n",
      "p = figure(plot_height = 600, plot_width = 800, \n",
      "               x_axis_label = 'X', \n",
      "               y_axis_label = 'Y')\n",
      "p2 = figure(plot_height = 600, plot_width = 800, \n",
      "               x_axis_label = 'X', \n",
      "               y_axis_label = 'Z')\n",
      "\n",
      "doc = curdoc()\n",
      "\n",
      "The data source is getting updated in an async loop:\n",
      "async def loop():\n",
      "    while True:\n",
      "        data = await socket.recv_pyobj()\n",
      "        new_data = get_last_data(data)\n",
      "        #update ColumnDataSource\n",
      "        doc.add_next_tick_callback(partial(update,new_data))\n",
      "\n",
      "doc.add_root(column(gridplot([p,p2], plot_width=1000)))\n",
      "\n",
      "try:        \n",
      "    testloop = IOLoop.current()\n",
      "    testloop.spawn_callback(loop)\n",
      "except KeyboardInterrupt:\n",
      "    testloop.close()\n",
      "\n",
      "and the ColumnDataSource is getting updated through the following function when new datapoints appear in the stream (parsed as a dataframe)\n",
      "def update(new_data):\n",
      "    input_data = dict(x=new_data['x'], y=new_data['y'], z=new_data['z'])\n",
      "    plot_data.stream(input_data, rollover=500)\n",
      "\n",
      "My initial idea for clearing the figures through a button click is the following:\n",
      "#Defining button for clearing plot\n",
      "button = Button(label=\"CLEAR PLOT\", button_type=\"danger\")\n",
      "def clear_plot(event):\n",
      "    plot_data = ColumnDataSource(dict(x=[],y=[],z=[]))\n",
      "button.on_event(ButtonClick,clear_plot)\n",
      "\n",
      "This is not working, and if I understand the stream method correctly, that is at the heart of the problem, as new data is continuously getting appended to the source and the above clear_plot function will not really clear the stream data source. How would one go about clearing the stream data source such that the figures are cleared?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070844/redis-in-dash-maximum-recursion-level-reached\n",
      "redis in Dash: Maximum recursion level reached\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am building a Dash application in Python 3.7. Specifically, I want to use redis for pre-computing an entire figure, but get an error \"Maximum recursion level reached.\"\n",
      "I follow \"Example 4\", \"Part 6, Sharing Data Between Callbacks\" of the official Dash Tutorial (https://dash.plot.ly/sharing-data-between-callbacks). However, in contrast to that example, I want to pre-compute not some data, but the entire figure. That is because I receive large datasets -- meteorological data over time -- that load very slowly because of their size, and hence I thought of pre-computing the figure beforehand. Anyway, I can built the app without the precompute part, but trying to modify it throws that error message from deep inside the Dash engine.\n",
      "import os, sys, uuid\n",
      "import dash_core_components as dcc\n",
      "import dash_html_components as html\n",
      "import dash\n",
      "import plotly\n",
      "from flask_caching import Cache\n",
      "import pandas\n",
      "import numpy\n",
      "\n",
      "sys.setrecursionlimit(500000)   # doesn't help!\n",
      "\n",
      "N = 50000   # big number\n",
      "\n",
      "# start Dash application\n",
      "app = dash.Dash(__name__)\n",
      "cache = Cache(app.server, config={\n",
      "    'CACHE_TYPE': 'redis',\n",
      "    'CACHE_DIR': 'cache-directory',\n",
      "    'CACHE_REDIS_URL': os.environ.get('REDIS_URL', 'redis://localhost:6379'),\n",
      "    'CACHE_THRESHOLD': 10\n",
      "})\n",
      "\n",
      "def get_dataframe(session_id):\n",
      "    @cache.memoize()\n",
      "    def query_and_serialize_data(session_id):\n",
      "        prep = pandas.DataFrame({\n",
      "            'data': [plotly.graph_objs.Scattergl(\n",
      "                x=[index for index in range(0, N)],   # time index\n",
      "                y=numpy.random.rand(N),               # data points\n",
      "                mode='lines+markers'\n",
      "            )]\n",
      "        })\n",
      "        return prep.to_json()\n",
      "    return pandas.read_json(query_and_serialize_data(session_id))\n",
      "\n",
      "def serve_layout():\n",
      "    session_id = str(uuid.uuid4())\n",
      "    return html.Div([\n",
      "        # hidden\n",
      "        html.Div(session_id, id='session-id', style={'display': 'none'}),\n",
      "        # graph\n",
      "        html.Div([dcc.Graph(id='graph')])\n",
      "    ])\n",
      "\n",
      "app.layout = serve_layout\n",
      "\n",
      "# update graph\n",
      "@app.callback(\n",
      "    dash.dependencies.Output('graph', 'figure'),\n",
      "    [dash.dependencies.Input('session-id', 'children')])\n",
      "def update_graph_figure(session_id):\n",
      "    #data = [plotly.graph_objs.Scattergl(\n",
      "    #    x=[index for index in range(0, N)],   # time index\n",
      "    #    y=numpy.random.rand(N),               # data points\n",
      "    #    mode='lines+markers'\n",
      "    #)]                                        # valid data to 'graph'\n",
      "    prep = get_dataframe(session_id)\n",
      "    return {'data': prep['data']}\n",
      "\n",
      "# main program\n",
      "if __name__ == '__main__':\n",
      "    app.run_server(debug=True)\n",
      "\n",
      "The error message follows a long call list:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2309, in call\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "...\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\", line 161, in _write\n",
      "    iso_dates, default_handler)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\", line 115, in _write\n",
      "    default_handler=default_handler\n",
      "OverflowError: Maximum recursion level reached  \n",
      "How should I correct the code? And if the very idea does not work, how can I speed up the load time in some other way?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070839/why-my-xpath-query-in-xml-file-does-not-work\n",
      "Why my xpath query in xml file does not work?\n",
      "\n",
      "\n",
      "I have huge xml and need xpath query to \"ПланыСтроки\" and other similar elements\n",
      "I open xml in firefox and copy xpath of node:\n",
      "/Документ/diffgr:diffgram/dsMMISDB/ПланыСтроки[1]\n",
      "\n",
      "and it does not work (i tested in https://codebeautify.org/Xpath-Tester, but and in python-lxml (when I need run that code) some results).\n",
      "The query runs well before the node\n",
      "/Документ/diffgr:diffgram\n",
      "\n",
      "and after that nothing match...\n",
      "XML:\n",
      "https://drive.google.com/file/d/19VQA-PpslQmcwdz-40MQ7cysDTvO7p_r/view?usp=sharing\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070794/how-to-remove-a-word-starting-with-hash-and-ending-with-either-a-space-or-dot\n",
      "How to remove a word starting with hash and ending with either a space or dot? [on hold]\n",
      "\n",
      "\n",
      "I want to remove words starting with hash ('#') and ending with blank (' ') or dot ('.'). \n",
      "E.g.: #words are #words. or these #words are harsh.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070793/how-to-change-value-of-variable-in-django-template\n",
      "How to change value of variable in django template?\n",
      "\n",
      "\n",
      "I want to declare a flag variable in django template and the change it if some thing happened.\n",
      "But when I change value of variable by custom tag it is declared a new variable and doesn't change.\n",
      "for example my template tag and django template is:\n",
      "template tag:\n",
      "@register.simple_tag\n",
      "def update_variable(value):\n",
      "    return  value\n",
      "\n",
      "html:\n",
      "{% with True as flag %}\n",
      "     <h1>1: {{ flag }}</h1>\n",
      "     {% for e in events %}\n",
      "         {% if e.title == '***' %}\n",
      "             {% update_variable False as flag %}\n",
      "             <h1>2: {{ flag }}</h1>\n",
      "         {% endif %}\n",
      "     {% endfor %}\n",
      "     <h1>3: {{ flag }}</h1>\n",
      "{% endwith %}\n",
      "\n",
      "and result is:\n",
      "1: True\n",
      "2: False\n",
      "3: True\n",
      "\n",
      "But the end result should be False! How to do this?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070784/ansible-using-variable-set-from-module\n",
      "Ansible using variable set from module\n",
      "\n",
      "\n",
      "i am trying to use value stored in a variable which is set from a custom module i have created for Solarwinds IPAM. The problem i am having is that am using two modules, my own and vmware_guest. In my module i am storing available IP address to argument \"ipaddr\" and trying to use that variable in provisioning.\n",
      "My tasks/main.yml file looks like this:\n",
      "---\n",
      "# tasks file for vmware_subnet_comibned\n",
      "- name: Finding available IP & setting DNS\n",
      "  SubnetExplorerAnsible:\n",
      "    hostname: \"{{ orion_hostname }}\"\n",
      "    username: \"{{ orion_username }}\"\n",
      "    password: \"{{ orion_password }}\"\n",
      "    server_name: \"{{ orion_server_name}}\"\n",
      "    subnet: \"{{ orion_subnet }}\"\n",
      "    dns_server_one: \"{{ orion_dns_server_one }}\"\n",
      "    dns_server_two: \"{{ orion_dns_server_two }}\"\n",
      "    dns_zone: \"{{ orion_dns_zone }}\"\n",
      "    ipaddr: \"{{ orion_ipaddr }}\"\n",
      "    subnet_mask: \"{{ orion_subnet_mask }}\"\n",
      "  register: result\n",
      "- debug: var=result\n",
      "\n",
      "- name: Cloning VMWare Template \"{{ template_name }}\"\n",
      "  vmware_guest:\n",
      "    hostname: \"{{ vcenter_hostname }}\"\n",
      "    username: \"{{ vcenter_username }}\"\n",
      "    password: \"{{ vcenter_password }}\"\n",
      "    validate_certs: \"{{ validate_certs }}\"\n",
      "\n",
      "    datacenter: \"{{ datacenter_name }}\"\n",
      "    cluster: \"{{ cluster_name }}\"\n",
      "    template: \"{{ template_name }}\"\n",
      "    datastore: \"{{ datastore_name }}\"\n",
      "    folder: \"{{ folder_name }}\"\n",
      "    name: \"{{ orion_server_name }}\"\n",
      "    disk:\n",
      "    - size_gb: \"{{ disk_size_gb }}\"\n",
      "      type: thin\n",
      "    hardware:\n",
      "      memory_mb: \"{{ memory_size_mb }}\"\n",
      "      num_cpus: \"{{ num_cpus }}\"\n",
      "    networks:\n",
      "    - name: \"{{ orion_subnet }}\"\n",
      "      type: static\n",
      "      ip: \"{{ orion_ipaddr }}\"\n",
      "      netmask: \"{{ orion_subnet_mask }}\"\n",
      "      gateway: \"{{ gateway }}\"\n",
      "      dns_servers:\n",
      "      - \"{{ orion_dns_server_one }}\"\n",
      "      - \"{{ orion_dns_server_two }}\"\n",
      "    wait_for_ip_address: yes\n",
      "    state: poweredon\n",
      "  delegate_to: localhost\n",
      "  register: result\n",
      "- debug: var=result\n",
      "\n",
      "For some reason i cannot copy ipaddr's value that is set from my ansible module because when i copy it, it returns null in provisioning.\n",
      "I do apologize for my bad explaining, hopefully someone will understand and be able to help me solve this problem. I will not share my module or playbook because it is not going to make anything more clear sadly.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070745/positioning-labels-and-color-coding-in-sunburst-r\n",
      "Positioning labels and color coding in sunburst - R\n",
      "\n",
      "\n",
      "This is what is the output.I have a data set which contains unit, weight of each unit and compliance score for each unit in year 2016. \n",
      "I was not able to add the table but here is the screenshot for the data in csv\n",
      "I have named the columns in the data as unit, weight and year(which is compliance score) . \n",
      "I want to create a sunburst chart where the first ring will be the unit divided based on weight and the second ring will be the same but will have labels compliance score. \n",
      "The colour for each ring will be different. \n",
      "I was able to do some code with the help from an online blog and the output I have gotten is similar to what I want but I am facing difficulty in positioning of the labels and also the colour coding for each ring\n",
      "#using ggplot\n",
      "library(ggplot2) # Visualisation\n",
      "library(dplyr) # data wrangling\n",
      "library(scales) # formatting\n",
      "\n",
      "#read file\n",
      "weight.eg = read.csv(\"Dummy Data.csv\", header = FALSE, sep = \n",
      "\";\",encoding = \"UTF-8\") \n",
      "\n",
      "#change column names\n",
      "colnames(weight.eg) <- c (\"unit\",\"weight\",\"year\")\n",
      "\n",
      "#as weight column is factor change into integer\n",
      "weight.eg$weight = as.numeric(levels(weight.eg$weight)) \n",
      "[as.integer(weight.eg$weight)]\n",
      "weight.eg$year = as.numeric(levels(weight.eg$year)) \n",
      "[as.integer(weight.eg$year)]\n",
      "#Nas are introduced, remove\n",
      "weight.eg <- na.omit(weight.eg)\n",
      "\n",
      "#Sum of the total weight\n",
      "sum_total_weight = sum(weight.eg$weight)\n",
      "\n",
      "#First layer\n",
      "firstLevel = weight.eg %>% summarize(total_weight=sum(weight))\n",
      "sunburst_0 = ggplot(firstLevel) # Just a foundation\n",
      "\n",
      "#this will generate a bar chart \n",
      "sunburst_1 = \n",
      "sunburst_0 + \n",
      "geom_bar(data=firstLevel, aes(x=1, y=total_weight), \n",
      "fill='darkgrey', stat='identity') +\n",
      "geom_text(aes(x=1, y=sum_total_weight/2, label=paste(\"Total \n",
      "Weight\", comma(total_weight))), color='black')\n",
      "#View  \n",
      "sunburst_1\n",
      "#this argument is used to rotate the plot around the y-axis which \n",
      "the total weight \n",
      "sunburst_1 + coord_polar(theta = \"y\")\n",
      "\n",
      "sunburst_2=\n",
      "sunburst_1 +\n",
      "geom_bar(data=weight.eg,\n",
      "       aes(x=2, y=weight.eg$weight, fill=weight.eg$weight),\n",
      "       color='white', position='stack', stat='identity', size=0.6) \n",
      "+ \n",
      "geom_text(data=weight.eg, aes(label=paste(weight.eg$unit, \n",
      "weight.eg$weight), x=2, y=weight.eg$weight), position='stack')\n",
      "\n",
      "sunburst_2 + coord_polar(theta = \"y\") \n",
      "\n",
      "sunburst_3 =\n",
      "sunburst_2 +\n",
      "geom_bar(data=weight.eg,\n",
      "       aes(x=3, y=weight.eg$weight,fill=weight.eg$weight),\n",
      "       color='white', position='stack', stat='identity', \n",
      "size=0.6)+\n",
      "geom_text(data = weight.eg, \n",
      "aes(label=paste(weight.eg$year),x=3,y=weight.eg$weight),position = \n",
      "'stack')  \n",
      "\n",
      "\n",
      "sunburst_3 + coord_polar(theta = \"y\") \n",
      "\n",
      "sunburst_3 + scale_y_continuous(labels=comma) + \n",
      "scale_fill_continuous(low='white', high='darkred') + \n",
      "coord_polar('y') + theme_minimal()\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070719/why-does-pycharm-automatically-hyperlink-my-url\n",
      "Why does PyCharm automatically hyperlink my URL\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whenever I paste a URL into my Python output window in PyCharm it automatically realizes that the URL is a link and when running the program that asks for the user to enter the URL it will automatically take you to the website instead of storing the URL in the input variable I made for it, \n",
      "I fixed this problem by removing the https:// for the URL and concatenation http:// to the URL after it's entered.\n",
      "But I want the user to be able to past the URL straight in without having to remove https://\n",
      "\n",
      "Answer\n",
      "\n",
      "strr=input(\"enter a url:\")[:-1]\n",
      "print(strr)\n",
      "\n",
      "by this user has to input whole website + one space then press enter. what else we can do for such bug..\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070691/problem-in-computing-perplexity-with-pytorch-example\n",
      "Problem in computing perplexity with pytorch example\n",
      "\n",
      "\n",
      "I am trying to train a language model with 2 bidirectional LSTM layer. I used to PyTorch language model example as my base code. I changed the layers so that fit the bidirectional mode. My problem is with computing perplexity! The perplexity computed by this base code is not valid when I am testing the bidirectional mode of LSTM cells.\n",
      "The code works ok when trying on unidirectional LSTM cells, i.e., the perplexity is a valid value.\n",
      "Here are the only changes I made in the base code model.py to make it compatible with bidirectional mode, I just edited the constructor and init_hidden methods:\n",
      "class RNNModel(nn.Module):\n",
      "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
      "\n",
      "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, tie_weights=False, bi_direction=False):\n",
      "        super(RNNModel, self).__init__()\n",
      "        self.drop = nn.Dropout(dropout)\n",
      "        self.encoder = nn.Embedding(ntoken, ninp)\n",
      "        self.bi_direction = bi_direction\n",
      "        if rnn_type in ['LSTM', 'GRU']:\n",
      "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout,\n",
      "                                             bidirectional=self.bi_direction)\n",
      "        else:\n",
      "            try:\n",
      "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
      "            except KeyError:\n",
      "                raise ValueError(\"\"\"An invalid option for `--model` was supplied,\n",
      "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
      "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout,\n",
      "                              bidirectional=self.bi_direction)\n",
      "\n",
      "        if self.bi_direction:\n",
      "            self.decoder = nn.Linear(nhid * 2, ntoken)\n",
      "            self.num_directions = 2\n",
      "        else:\n",
      "            self.decoder = nn.Linear(nhid, ntoken)\n",
      "            self.num_directions = 1\n",
      "\n",
      "        # Optionally tie weights as in:\n",
      "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
      "        # https://arxiv.org/abs/1608.05859\n",
      "        # and\n",
      "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\"\n",
      "        # (Inan et al. 2016)\n",
      "        # https://arxiv.org/abs/1611.01462\n",
      "        if tie_weights:\n",
      "            if nhid != ninp:\n",
      "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
      "            self.decoder.weight = self.encoder.weight\n",
      "\n",
      "        self.init_weights()\n",
      "        self.rnn_type = rnn_type\n",
      "        self.nhid = nhid\n",
      "        self.nlayers = nlayers\n",
      "\n",
      "\n",
      "And here is how the weights are initialized:\n",
      "    def init_hidden(self, bsz):\n",
      "        \"\"\"\n",
      "        Initialising [bsz] number of hidden cells of LSTM layers\n",
      "        :param bsz: batch size\n",
      "        :return: Initialised weights of hidden cells [h + c]\n",
      "        \"\"\"\n",
      "        weight = next(self.parameters())\n",
      "        if self.rnn_type == 'LSTM':\n",
      "            return (weight.new_zeros(self.nlayers * self.num_directions, bsz, self.nhid),\n",
      "                    weight.new_zeros(self.nlayers * self.num_directions, bsz, self.nhid))\n",
      "        return weight.new_zeros(self.nlayers * self.num_directions, bsz, self.nhid)\n",
      "\n",
      "\n",
      "The perplexity for my corpus when using the default unidirectional mode is about 60 after the training finished but when I am using bidirectional mode the perplexity reaches about 2 after training for a few batches during the first epoch.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070684/django-server-just-stops\n",
      "Django Server Just Stops\n",
      "\n",
      "\n",
      "I just got done upgrading to Django 2.2.3 from version 2.0.\n",
      "For some reason the system will just stop working when going to a new page.  I might go one or to pages and then the server stops.\n",
      "I am also using Cookiecutter.\n",
      "Below is a typical message that I am receiving.  Though it changes.\n",
      "it was acting strange before this - why I upgraded.\n",
      "I checked all my migrations.  Reinstalled Django.  Using Pycharm.\n",
      "Thanks.\n",
      "[17/Jul/2019 06:21:45] \"GET /case/index/4QUxNe8vSNkd/ HTTP/1.1\" 200 1259481\n",
      "[17/Jul/2019 06:21:45] \"GET /static/CACHE/css/app.128af5d916e2.css HTTP/1.1\" 200 356184\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/manage.py\", line 29, in <module>\n",
      "    execute_from_command_line(sys.argv)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/core/management/__init__.py\", line 381, in execute_from_command_line\n",
      "    utility.execute()\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/core/management/__init__.py\", line 375, in execute\n",
      "    self.fetch_command(subcommand).run_from_argv(self.argv)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/core/management/base.py\", line 323, in run_from_argv\n",
      "    self.execute(*args, **cmd_options)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/core/management/commands/runserver.py\", line 60, in execute\n",
      "    super().execute(*args, **options)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/core/management/base.py\", line 364, in execute\n",
      "    output = self.handle(*args, **options)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/core/management/commands/runserver.py\", line 95, in handle\n",
      "    self.run(**options)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/core/management/commands/runserver.py\", line 102, in run\n",
      "    autoreload.run_with_reloader(self.inner_run, **options)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 587, in run_with_reloader\n",
      "    start_django(reloader, main_func, *args, **kwargs)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 572, in start_django\n",
      "    reloader.run(django_main_thread)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 290, in run\n",
      "    self.run_loop()\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 296, in run_loop\n",
      "    next(ticker)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 336, in tick\n",
      "    for filepath, mtime in self.snapshot_files():\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 352, in snapshot_files\n",
      "    for file in self.watched_files():\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 251, in watched_files\n",
      "    yield from iter_all_python_module_files()\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 103, in iter_all_python_module_files\n",
      "    return iter_modules_and_files(modules, frozenset(_error_files))\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/django/utils/autoreload.py\", line 116, in iter_modules_and_files\n",
      "    if module.__name__ == '__main__':\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/py/_apipkg.py\", line 171, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"/Users/benson/PycharmProjects/myanalysis/v_env/lib/python3.6/site-packages/py/_error.py\", line 44, in __getattr__\n",
      "    raise AttributeError(name)\n",
      "AttributeError: __name__\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070660/how-to-access-firebase-firestore-python-trigger-event-data\n",
      "How to Access Firebase Firestore Python Trigger Event Data?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this some sort of format that I'm not familiar with in Python? I'm wondering because I'm not sure if there's a better way to access these values.\n",
      "The documentation doesn't show clear information on how to access variables, and being a cloud service, the cycle in debugging this data is EXTREMELY slow - At least 4 minutes\n",
      "On a Firestore Trigger\n",
      "def job_trigger(data, context):\n",
      "    print(data[\"oldValue\"])\n",
      "\n",
      "The output is:\n",
      "{\"createTime\": \"2019-07-14T19:26:54.577250Z\", \n",
      "\"fields\": {\"0\": {\"integerValue\": \"0\"}, \"14\": {\"integerValue\": \"73\"}, \"2\": {\"integerValue\": \"17\"}, \"20\": {\"integerValue\": \"91\"}, \"30\": {\"integerValue\": \"150\"}, \"4\": {\"integerValue\": \"29\"}, \"5\": {\"integerValue\": \"30\"}, \"7\": {\"integerValue\": \"36\"}}, \n",
      "\"name\": \"projects/aerial-grid-233801/databases/(default)/documents/jobData/weWereYoung/overrides/indexOverrides\", \"updateTime\": \"2019-07-17T06:57:41.153135Z\"}\n",
      "\n",
      "Do I have to access data through data[\"oldValue\"][\"fields\"][\"0\"]? Or something similar. This actually isn't working either...\n",
      "I'm finding this format extremely hard to deal with and would've just converted my project to Javascript had I known? Unless I'm missing something about it.\n",
      "Can I access these variables in an easier way?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070637/osmnx-does-not-download-the-maps-on-mac-osx\n",
      "osmnx does not download the maps on mac (osX)\n",
      "\n",
      "\n",
      "So I just moved from win to mac with a project that worked fine. \n",
      "We were downloading graph with this on Windows:\n",
      "G = ox.graph_from_place('Delft, Netherlands', network_type='drive')\n",
      "\n",
      "but now with Mac it just runs forever and is stuck with this code.\n",
      "I installed osmnx via conda-forge. \n",
      "The code is on github and it works on Windows, but not on Mac.\n",
      "PS. Before I had 'Shell is not a LinerRing' issue, which I solved with reinstalling geopandas from pip.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070616/uniqueconstraint-in-django-2-2-dont-raise-validationerror\n",
      "UniqueConstraint in django 2.2 don't raise ValidationError\n",
      "\n",
      "\n",
      "Since django 2.2 docs recommend to use UniqueConstraint instead of unique_together, but this option didn't raise ValidationError in django admin without overriding clean or validate_unique methods.\n",
      "Is it possible to make UniqueConstraint raise ValidationError(in django admin) instead of IntegrityError without implementing validation logic by myself?\n",
      "\n",
      "Answer\n",
      "\n",
      "According to the documentation, UniqueConstraint already does what you're asking:\n",
      "\n",
      "In general constraints are not checked during full_clean(), and do not raise ValidationErrors. Rather you’ll get a database integrity error on save(). UniqueConstraints are different in this regard, in that they leverage the existing validate_unique() logic, and thus enable two-stage validation. In addition to IntegrityError on save(), ValidationError is also raised during model validation when the UniqueConstraint is violated.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070594/make-and-populate-a-pyspark-dataframe-with-columns-as-period-range\n",
      "Make and populate a PySpark dataframe with columns as period_range\n",
      "\n",
      "\n",
      "I have a PySpark dataframe like this\n",
      "+----------+--------+----------+----------+\n",
      "|id_       | p      |d1        |  d2      |\n",
      "+----------+--------+----------+----------+\n",
      "|  1       | A      |2018-09-26|2018-10-26|\n",
      "|  2       | B      |2018-06-21|2018-07-19|\n",
      "|  2       | B      |2018-08-13|2018-10-07|\n",
      "|  2       | B      |2018-12-31|2019-02-27|\n",
      "|  2       | B      |2019-05-28|2019-06-25|\n",
      "|  3       |C       |2018-06-15|2018-07-13|\n",
      "|  3       |C       |2018-08-15|2018-10-09|\n",
      "|  3       |C       |2018-12-03|2019-03-12|\n",
      "|  3       |C       |2019-05-10|2019-06-07|\n",
      "| 4        | A      |2019-01-30|2019-03-01|\n",
      "| 4        | A      |2019-05-30|2019-07-25|\n",
      "| 5        |C       |2018-09-19|2018-10-17|\n",
      "-------------------------------------------\n",
      "\n",
      "From this I want to create and populate another Pyspark dataframe which have n columns ranging from min(d1) to max(d2) and each column is a date in that range.\n",
      "I want to populate this dataframe with 1 and 0 for each row.\n",
      "For row 1 I want populate all the days in the range min(d1 of row 1) to max(d1 of row 1) with 1 and rest columns with a 0. Similarly for all the rows in the dataframe.\n",
      "I was doing something like this in pandas for this purpose.\n",
      "result = pd.DataFrame(data = 0, columns=pd.period_range(data['d1'].min(), data['d2'].max(), freq='D'), index=data.index)\n",
      "\n",
      "for c in result.columns:\n",
      "    result[c] = np.where((c.d2>=data.d1)&(c.d1 <= data.d2), 1, 0)\n",
      "\n",
      "How to do the same in PySpark.?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070579/substitution-local-date-or-datetime-for-iso-8601-in-string\n",
      "Substitution local date or datetime for ISO 8601 in string\n",
      "\n",
      "\n",
      "I try to substitute local date or datetime (+02:00) for ISO 8601 \"YYYY-MM-DDTHH:MI:SSZ\" (UTC) in string in python 3.x\n",
      "String example:\n",
      "x = \"This is first example with dates 2019-07-01 21:30:20 and 2019-07-02 21:30:20\"\n",
      "\n",
      "My code, which works fine but not perfect:\n",
      "def date_to_iso(m):\n",
      "    date_string = (dateutil.parser.parse(m.group(0))).astimezone(pytz.UTC).strftime(\"%Y-%m-%d\" + \"T\" + \"%H:%M:%S\" + \"Z\")\n",
      "    return iso_8601\n",
      "\n",
      "y = re.sub(r\"\\d{4}(?:-\\d{2}){2}\" + r\" \\d{2}(?::\\d{2}){2}\", date_to_iso, x)\n",
      "\n",
      "And result is good for first example:\n",
      "Out[269]: 'This is first example with dates 2019-07-01T19:30:20Z and 2019-07-02T19:30:20Z'\n",
      "\n",
      "My question is how to modify it for possibility to have dates in different formats. For example:\n",
      "x = \"This is second example with dates 2019-07-01 and 2019-07-02 21:30:20, but there are dates 2019-07-10 07:00 and 2019-07-10 09 too\"\n",
      "\n",
      "and it should return something like this:\n",
      "Out[269]: 'This is second example with dates 2019-06-30T22:00:00Z and 2019-07-02T19:30:20Z, but there are dates 2019-07-10T05:00:00Z or 2019-07-10T07:00:00Z'\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070535/calling-fortran-subroutine-in-python-returns-nonetype\n",
      "Calling Fortran subroutine in Python returns 'NoneType'\n",
      "\n",
      "\n",
      "I want to write a Python package containing the essential features of R's KernSmooth package maintained by Brian Ripley. Most of the code for R's KernSmooth is written in Fortran77 syntax. So basically mimicking what Brian Ripley did in R, my plan is to import the Fortran subroutines into Python and write the corresponding user interface. As a start, I'd like to put the Fortran77 subroutine rlbin.f (code below) inside a Python function.\n",
      "c  Part of R package KernSmooth\n",
      "c  Copyright (C) 1995  M. P. Wand\n",
      "c\n",
      "c  Unlimited use and distribution (see LICENCE).\n",
      "\n",
      "cccccccccc FORTRAN subroutine rlbin.f cccccccccc\n",
      "\n",
      "c Obtains bin counts for univariate regression data\n",
      "c via the linear binning strategy. If \"trun=0\" then\n",
      "c weight from end observations is given to corresponding\n",
      "c end grid points. If \"trun=1\" then end observations\n",
      "c are truncated.\n",
      "\n",
      "c Last changed: 26 MAR 2009\n",
      "\n",
      "      subroutine rlbin(X,Y,n,a,b,M,trun,xcnts,ycnts)\n",
      "      double precision X(*),Y(*),a,b,xcnts(*),ycnts(*),lxi,delta,rem\n",
      "      integer n,M,i,li,trun\n",
      "\n",
      "c     Initialize grid counts to zero\n",
      "\n",
      "      do 10 i=1,M\n",
      "         xcnts(i) = dble(0)\n",
      "         ycnts(i) = dble(0)\n",
      "10    continue\n",
      "\n",
      "      delta = (b-a)/(M-1)\n",
      "      do 20 i=1,n\n",
      "         lxi = ((X(i)-a)/delta) + 1\n",
      "\n",
      "c        Find integer part of \"lxi\"\n",
      "\n",
      "         li = int(lxi) \n",
      "         rem = lxi - li\n",
      "         if (li.ge.1.and.li.lt.M) then\n",
      "            xcnts(li) = xcnts(li) + (1-rem)\n",
      "            xcnts(li+1) = xcnts(li+1) + rem\n",
      "            ycnts(li) = ycnts(li) + (1-rem)*y(i)\n",
      "            ycnts(li+1) = ycnts(li+1) + rem*y(i)\n",
      "         endif\n",
      "\n",
      "         if (li.lt.1.and.trun.eq.0) then\n",
      "            xcnts(1) = xcnts(1) + 1\n",
      "            ycnts(1) = ycnts(1) + y(i)\n",
      "         endif      \n",
      "\n",
      "         if (li.ge.M.and.trun.eq.0) then \n",
      "               xcnts(M) = xcnts(M) + 1\n",
      "               ycnts(M) = ycnts(M) + y(i)\n",
      "         endif\n",
      "\n",
      "20    continue\n",
      "\n",
      "      return\n",
      "      end\n",
      "\n",
      "cccccccccc End of rlbin.f cccccccccc\n",
      "\n",
      "I already successfully compiled the Fortran code and imported it into Python.\n",
      "In the Unix shell I typed\n",
      "f2py -c -m rlbin rlbin.f\n",
      "\n",
      "creating a shared library rlbin.so which I imported into Python:\n",
      "import rlbin\n",
      "\n",
      "print(rlbin.__doc__)\n",
      "\n",
      "Output:\n",
      "This module 'rlbin' is auto-generated with f2py (version:2).\n",
      "Functions:\n",
      "  rlbin(x,y,n,a,b,m,trun,xcnts,ycnts)\n",
      ".\n",
      "\n",
      "print(rlbin.rlbin.__doc__)\n",
      "\n",
      "Output:\n",
      "rlbin(x,y,n,a,b,m,trun,xcnts,ycnts)\n",
      "\n",
      "Wrapper for ``rlbin``.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x : input rank-1 array('d') with bounds (*)\n",
      "y : input rank-1 array('d') with bounds (*)\n",
      "n : input int\n",
      "a : input float\n",
      "b : input float\n",
      "m : input int\n",
      "trun : input int\n",
      "xcnts : input rank-1 array('d') with bounds (*)\n",
      "ycnts : input rank-1 array('d') with bounds (*)\n",
      "\n",
      "I specified the input parameters as follows:\n",
      "import numpy as np\n",
      "\n",
      "# create random x and y arrays\n",
      "x = np.ndarray(shape=(2000,), dtype=float, order='F')\n",
      "y = np.ndarray(shape=(2000,), dtype=float, order='F')\n",
      "\n",
      "n = len(x)\n",
      "a = 0.05\n",
      "b = 0.995\n",
      "M = 500\n",
      "trun = 1\n",
      "\n",
      "xcents = np.zeros(M)\n",
      "ycnts = np.zeros(M)\n",
      "\n",
      "\n",
      "I checked the data types: a and b are indeed floats; n, M, and trun are integers; x, y, xcnst and ycnts are numpy arrays.\n",
      "And called the Fortran subroutine\n",
      "out = rlbin.rlbin(x, y, n, a, b, M, trun, xcnts, ycnts)\n",
      "\n",
      "which executes without error. Similarly, calling out does not throw an error but does not return anything either.\n",
      "type(out)however returns NoneType and\n",
      "print(out) returns None.\n",
      "I tried the same procedure (compile, import, call) in R and it worked without any problems.\n",
      "For the ones interested, the corresponding R call would be (taken from the all.R script, lines 713-724):\n",
      "out <- .Fortran(\"rlbin\", as.double(x), as.double(y), as.integer(n),\n",
      "                  as.double(a), as.double(b), as.integer(M),  as.integer(trun), double(M), double(M))\n",
      "\n",
      "I already followed a few tutorials to check if my f2py environment is set up properly and yes, I have no issues calling other Fortran subroutines in Python:\n",
      "\n",
      "https://notmatthancock.github.io/2017/02/10/calling-fortran-from-python.html\n",
      "https://notmatthancock.github.io/2017/03/07/multiple-modules-with-f2py.html\n",
      "https://www-uxsup.csx.cam.ac.uk/courses/moved.PythonFortran/f2py.pdf (tutorial)\n",
      "https://git.physics.byu.edu/dfvankom/python-learning/tree/master/python-fortran (data)\n",
      "\n",
      "So what irritates me is that calling the exact same Fortran subroutine in R using the exact same input parameters works flawlessly. Maybe Python handles the input parameters differently than R does, but I don't see how at this point. \n",
      "I appreciate any help!\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070524/cannot-run-py-script-on-screen\n",
      "Cannot run .py script on screen\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am trying to run .py script on Linux screen. Once I create the screen I change direction to the location of the script and next trying to run it:\n",
      "python script_name.py, but any response. Could you please advise to resolve it? Thank you in advance.\n",
      "I tried to:\n",
      "1. screen -S screen_name\n",
      "2. cd location_of_the_script\n",
      "3. python script_name.py\n",
      "I woule like to have my script running on the screen and then deattache from this screen.\n",
      "\n",
      "Answer\n",
      "\n",
      "screen -S <name> (make screen name)\n",
      "screen -r <name> (attach if you are not attached, but you should be)\n",
      "cd /location/of/script (get to your script)\n",
      "python your_script.py (run your script)\n",
      "^a d that is, Ctl + a, then d (detach from screen)\n",
      "Here is a link to a Linux screen cheat sheet:\n",
      "http://aperiodic.net/screen/quick_reference\n",
      "I would also recommend using tmux instead of Linux screen.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070509/model-suggestion-for-detection-of-malware-based-on-multiple-api-call-sequences\n",
      "Model suggestion for detection of malware based on multiple api call sequences\n",
      "\n",
      "\n",
      "I'm trying to build a RNN (LSTM) model for classification of binary as benign/malware. The data structure I've presently looks as follows\n",
      "{\n",
      "    \"binary1\": {\n",
      "        \"label\": 1,\n",
      "        \"sequences\": [\n",
      "            [\"api1\",\"api2\",\"api3\", ...],\n",
      "            [\"api1\",\"api2\",\"api3\", ...],\n",
      "            [\"api1\",\"api2\",\"api3\", ...],\n",
      "            [\"api1\",\"api2\",\"api3\", ...],\n",
      "            ...\n",
      "        ]\n",
      "    },\n",
      "    \"binary2\": {\n",
      "        \"label\": 0,\n",
      "        \"sequences\": [\n",
      "            [\"api1\",\"api2\",\"api3\", ...],\n",
      "            [\"api1\",\"api2\",\"api3\", ...],\n",
      "            [\"api1\",\"api2\",\"api3\", ...],\n",
      "            [\"api1\",\"api2\",\"api3\", ...],\n",
      "            ...\n",
      "        ]\n",
      "    },\n",
      "    ...\n",
      "}\n",
      "\n",
      "Here each binary have variable number of sequences, and each sequence have variable number of API calls.\n",
      "I can pad the data so that all binaries will have equal number of sequences and each sequence also have equal number of API calls.\n",
      "But my question is how can I use this data for training?\n",
      "The problem is that, all the sequences of the malicious binary may not be malicious sequences. So, if I use the label and indicate the model that all those sequences are malicious and if some of the sequences are similar in benign files also, the benign binary may be treated as malware.\n",
      "To better understand the problem, treat each binary as a person on twitter, and each API call sequences as a words in a tweet. A user may tweet so many tweets, but a few of them may be about sports (for eg). And in my training data I know which persons tweets about sports, but I don't know which tweets are about sports. So, what I'm trying to do is classifying those persons whether they like sports or not based on all the tweets of the person.\n",
      "In the same way, I know whether the binary is malicious or not, but I don't know which API call sequences are responsible for maliciousness. And I want the model to identify those sequences from the training data. Is it possible? And what architecture should I use?\n",
      "Hope I conveyed my question, thanks for reading and waiting for a suggestion.\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070492/hide-text-opencv\n",
      "Hide Text OpenCV\n",
      "\n",
      "\n",
      "I want to show only one expression's label while detecting for face expression\n",
      " for (x,y,w,h) in faces:\n",
      "    segiempat=cv2.rectangle(frame, (x,y), (x+w, y+h), (255,255,255), 3) #rectangle untuk deteksi wajah\n",
      "\n",
      "    roi_gray = gray[y:y+h, x:x+w]\n",
      "    roi_color = frame[y:y+h, x:x+w]\n",
      "    cv2.putText(frame,'Wajah',(x+5,y-10), font, 0.5, (255,255,255))\n",
      "\n",
      "    angry = angry_cascade.detectMultiScale(roi_gray, 1.1, 2)\n",
      "    happy = happy_cascade.detectMultiScale(roi_gray, 1.1, 1)\n",
      "    sad = sad_cascade.detectMultiScale(roi_gray,1.1,2)\n",
      "    for (ax, ay, aw, ah) in angry:\n",
      "        cv2.putText(frame,'Angry',(x+5,y+55), font, 0.5, (191, 19, 33)) \n",
      "\n",
      "\n",
      "    for (hx, hy, hw, hh) in happy:\n",
      "        cv2.putText(frame, 'Happy', (x+5,y+35),font, 0.5, (27, 204, 4))\n",
      "\n",
      "\n",
      "    for (sx, sy, sw, sh) in sad:\n",
      "        cv2.putText(frame, 'Sad', (x+5,y+75),font, 0.5, (246, 255, 0))\n",
      "\n",
      "I expect the output to show only one label\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070490/how-can-i-create-multiple-consumers-and-read-data-from-the-same-number-of-partit\n",
      "How can I create multiple consumers and read data from the same number of partitions of the same topic in python?\n",
      "\n",
      "\n",
      "I want to create multiple consumers and read data from multiple partitions.If I want to create multiple partitions I can create using the command line as follows:\n",
      "python pykafka/cli/kafka_tools.py --broker_version 0.10.1 create_topic --num_partitions 3\n",
      "\n",
      "But how can I create multiple consumers? Is this as follows or is there any other method?\n",
      "consumer = KafkaConsumer('my-topic', bootstrap_servers='localhost:9092')\n",
      "consumer2 = KafkaConsumer('my-topic', bootstrap_servers='localhost:9092')\n",
      "\n",
      "But this doesnt look tidy. And If I have multiple paritions(same number) then how can I coalesce all data from partitions to single record.\n",
      "I followed this question\n",
      "But It looks round about for me and If I have to streams API how am to implement it .Can you just give me a demo program?\n",
      "\n",
      "Answer\n",
      "\n",
      "no\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57070487/filter-data-from-python-plot\n",
      "Filter data from python plot\n",
      "\n",
      "\n",
      "I'm trying to filter some data from my plot. Specifically it is the 'hair' at the top of the cycle that I wish to remove.\n",
      "The 'hair' is due to some numerical errors and I'm not aware of any method in python or how to write a code that would filter away points that don't occur frequently.\n",
      "I wish to filter the data as I plot it.\n",
      "\n",
      "Answer\n",
      "\n",
      "You can use Smooth function for this. to get rid of noice,\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Plot the Raw Data\n",
      "# plt. Your Data >>>Bla Bla Blaa\n",
      "\n",
      "smooth_data = pd.rolling_mean(ts,5).plot(style='k')\n",
      "plt.show()\n",
      "======================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "page= urlopen(\"https://stackoverflow.com/questions/tagged/python\")\n",
    "document=page.read()\n",
    "soup=BeautifulSoup(document, 'html.parser')\n",
    "questions=soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "# questions=[]\n",
    "for questions in questions_list:\n",
    "    print(\"Question\\n\")\n",
    "    print('http://stackoverflow.com'+questions.get('href'))\n",
    "    print(questions.get_text())\n",
    "    print(\"\\n\")\n",
    "    url='https://stackoverflow.com'+questions.get('href')\n",
    "    response = req.urlopen(url)\n",
    "    soup= BeautifulSoup(response,'html.parser')\n",
    "    for question in soup.select(\"div.postcell div.post-text\"):\n",
    "        print(question.get_text().strip())\n",
    "    print(\"\\nAnswer\\n\")\n",
    "    if len(soup.select(\"div.answercell div.post-text\"))==0:\n",
    "        print('no answer')\n",
    "    else:\n",
    "        for answer in soup.select(\"div.answercell div.post-text\"):\n",
    "            print(answer.get_text().strip())\n",
    "\n",
    "    print('='*40,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site =\"https://kin.naver.com/search/list.nhn?\"\n",
    "tag = input(\"검색어를 입력해주십시오-->\")\n",
    "num = input(\"검색할 페이지 번호를 입력하십시오-->\")\n",
    "temp_url = site + \"sort=none&query=\" + tag \n",
    "temp_url_encode=parse.urlparse(temp_url)\n",
    "query = parse.parse_qs(temp_url_encode.query)\n",
    "query_encode = parse.urlencode(query, doseq=True)\n",
    "\n",
    "url = site+query_encode+\"&section=kin&page=\"+ num\n",
    "\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "soup = BeautifulSoup(document.decode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "temp_qna = soup.find(class_=\"basic1\")\n",
    "qna_list = temp_qna.select(\"li > dl > dt > a\")\n",
    "\n",
    "for qna in qna_list:\n",
    "    qna_url = qna.attrs[\"href\"]\n",
    "    print(\"=\"*30+\"링크\"+\"=\"*30)\n",
    "    print(qna_url)\n",
    "    \n",
    "    # 링크 읽기\n",
    "    qna_page = urlopen(qna_url.encode(\"ascii\",\"ignore\").decode(\"ascii\",\"ignore\")) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성\n",
    "    soup_qna = BeautifulSoup(qna_document.decode(\"utf-8\"), \"html.parser\")\n",
    "    \n",
    "    # 질문\n",
    "    print(\"*\"*10 + \"질문 제목\")\n",
    "    qna_questions = soup_qna.find(class_=\"question-content__inner\")\n",
    "    \n",
    "    if qna_questions == None:\n",
    "        pass\n",
    "    else:\n",
    "        title_q = qna_questions.select_one(\"div.c-heading > div.c-heading__title > div.c-heading__title-inner > div.title\").text\n",
    "        print(title_q.strip())\n",
    "    \n",
    "    content_q = qna_questions.select_one(\"div.c-heading > div.c-heading__content\")\n",
    "    if content_q == None:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*10 + \"질문 내용\")\n",
    "        print(content_q.text.strip())\n",
    "        \n",
    "    # 답변\n",
    "    qna_answers = soup_qna.find(class_=\"answer-content__inner\")\n",
    "    \n",
    "    title_q_list = qna_answers.select(\"div.c-heading-answer__title > p\")\n",
    "    content_q_list = qna_answers.select(\"div._endContentsText\")\n",
    "    \n",
    "    if title_q == None:\n",
    "        print(\"답변이 없습니다\")\n",
    "    else:\n",
    "        for title_q in title_q_list:\n",
    "            for content_q in content_q_list:\n",
    "                print(\"\\n\")\n",
    "                print(\"+\"*10 + \"답변자\" + \"+\"*10)\n",
    "                print(title_q.text.strip())\n",
    "                print(\"+\"*26)\n",
    "                print(\"\\n\")\n",
    "                print(\"-\"*10 + \"답변 내용\" + \"-\"*10)\n",
    "                print(content_q.text.strip())\n",
    "                print(\"-\"*29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
