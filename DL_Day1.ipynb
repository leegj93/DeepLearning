{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 15:33:24.454030 18148 deprecation.py:323] From <ipython-input-3-8fff32bca56b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0806 15:33:24.461003 18148 deprecation.py:323] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0806 15:33:24.468983 18148 deprecation.py:323] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 15:33:24.876892 18148 deprecation.py:323] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0806 15:33:24.885870 18148 deprecation.py:323] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0806 15:33:24.969644 18148 deprecation.py:323] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "training_epochs=15\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 15:33:25.562061 18148 deprecation.py:323] From <ipython-input-5-c9d1165c4237>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() #그래프에 있는 모든 텐서를 초기화\n",
    "x=tf.placeholder(tf.float32, [None,784])\n",
    "y=tf.placeholder(tf.float32, [None,10])\n",
    "w1=tf.get_variable(\"w1\", shape=[784,256],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1=tf.Variable(tf.random_normal([256]))\n",
    "L1=tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "\n",
    "w2=tf.get_variable(\"w2\", shape=[256,256],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2=tf.Variable(tf.random_normal([256]))\n",
    "L2=tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
    "\n",
    "w3=tf.get_variable(\"w3\", shape=[256,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3=tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "hf= tf.matmul(L2,w3)+b3\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n",
    "               (logits=hf, labels=y))\n",
    "train=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.308360720\n",
      "cost: 0.111059045\n",
      "cost: 0.071581779\n",
      "cost: 0.052648885\n",
      "cost: 0.039059533\n",
      "cost: 0.029589023\n",
      "cost: 0.023052109\n",
      "cost: 0.016883144\n",
      "cost: 0.017983242\n",
      "cost: 0.016018108\n",
      "cost: 0.010364747\n",
      "cost: 0.010204323\n",
      "cost: 0.013252093\n",
      "cost: 0.010666394\n",
      "cost: 0.006442710\n",
      "acc: 0.9792\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    total_batch=int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batchxs,batchys=mnist.train.next_batch(batch_size)\n",
    "        myfeed={x:batchxs, y:batchys}\n",
    "        cv,_=sess.run([cost, train], feed_dict=myfeed)\n",
    "        avg_cost+=cv/total_batch\n",
    "    print('cost:','{:.9f}'.format(avg_cost))\n",
    "\n",
    "c_pre=tf.equal(tf.argmax(hf, 1), tf.argmax(y,1))\n",
    "acc=tf.reduce_mean(tf.cast(c_pre, tf.float32))\n",
    "print('acc:', sess.run(acc, feed_dict=\n",
    "                       {x:mnist.test.images, \n",
    "                        y:mnist.test.labels}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #그래프에 있는 모든 텐서를 초기화\n",
    "x=tf.placeholder(tf.float32, [None,784])\n",
    "y=tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "w1=tf.get_variable(\"w1\", shape=[784,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1=tf.Variable(tf.random_normal([512]))\n",
    "L1=tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "\n",
    "w2=tf.get_variable(\"w2\", shape=[512,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2=tf.Variable(tf.random_normal([512]))\n",
    "L2=tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
    "\n",
    "w3=tf.get_variable(\"w3\", shape=[512,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3=tf.Variable(tf.random_normal([512]))\n",
    "L3=tf.nn.relu(tf.matmul(L2,w3)+b3)\n",
    "\n",
    "w4=tf.get_variable(\"w4\", shape=[512,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4=tf.Variable(tf.random_normal([512]))\n",
    "L4=tf.nn.relu(tf.matmul(L3,w4)+b4)\n",
    "\n",
    "w5=tf.get_variable(\"w5\", shape=[512,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5=tf.Variable(tf.random_normal([10]))\n",
    "hf=tf.matmul(L4,w5)+b5\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n",
    "               (logits=hf, labels=y))\n",
    "train=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.311542185\n",
      "cost: 0.103263652\n",
      "cost: 0.070800507\n",
      "cost: 0.053177472\n",
      "cost: 0.039215527\n",
      "cost: 0.035896276\n",
      "cost: 0.030569362\n",
      "cost: 0.025791395\n",
      "cost: 0.020981824\n",
      "cost: 0.020992733\n",
      "cost: 0.018921957\n",
      "cost: 0.017222322\n",
      "cost: 0.016345381\n",
      "cost: 0.015898871\n",
      "cost: 0.012514134\n",
      "acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    total_batch=int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batchxs,batchys=mnist.train.next_batch(batch_size)\n",
    "        myfeed={x:batchxs, y:batchys}\n",
    "        cv,_=sess.run([cost, train], feed_dict=myfeed)\n",
    "        avg_cost+=cv/total_batch\n",
    "    print('cost:','{:.9f}'.format(avg_cost))\n",
    "\n",
    "c_pre=tf.equal(tf.argmax(hf, 1), tf.argmax(y,1))\n",
    "acc=tf.reduce_mean(tf.cast(c_pre, tf.float32))\n",
    "print('acc:', sess.run(acc, feed_dict=\n",
    "                       {x:mnist.test.images, \n",
    "                        y:mnist.test.labels}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 15:37:00.136117 18148 deprecation.py:506] From <ipython-input-9-828d1abeed02>:10: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() #그래프에 있는 모든 텐서를 초기화\n",
    "x=tf.placeholder(tf.float32, [None,784])\n",
    "y=tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "w1=tf.get_variable(\"w1\", shape=[784,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1=tf.Variable(tf.random_normal([512]))\n",
    "L1=tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "L1=tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "w2=tf.get_variable(\"w2\", shape=[512,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2=tf.Variable(tf.random_normal([512]))\n",
    "L2=tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
    "L2=tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "w3=tf.get_variable(\"w3\", shape=[512,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3=tf.Variable(tf.random_normal([512]))\n",
    "L3=tf.nn.relu(tf.matmul(L2,w3)+b3)\n",
    "L3=tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "w4=tf.get_variable(\"w4\", shape=[512,512],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4=tf.Variable(tf.random_normal([512]))\n",
    "L4=tf.nn.relu(tf.matmul(L3,w4)+b4)\n",
    "L4=tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "w5=tf.get_variable(\"w5\", shape=[512,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5=tf.Variable(tf.random_normal([10]))\n",
    "hf=tf.matmul(L4,w5)+b5\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n",
    "               (logits=hf, labels=y))\n",
    "train=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 0.468760225\n",
      "cost: 0.171969657\n",
      "cost: 0.130195387\n",
      "cost: 0.107142114\n",
      "cost: 0.091269707\n",
      "cost: 0.080496163\n",
      "cost: 0.074153927\n",
      "cost: 0.067710757\n",
      "cost: 0.064185572\n",
      "cost: 0.059730153\n",
      "cost: 0.052141268\n",
      "cost: 0.052297199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-033500068527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mbatchxs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmyfeed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatchxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatchys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mavg_cost\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cost:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'{:.9f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    total_batch=int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batchxs,batchys=mnist.train.next_batch(batch_size)\n",
    "        myfeed={x:batchxs, y:batchys, keep_prob:0.7}\n",
    "        cv,_=sess.run([cost, train], feed_dict=myfeed)\n",
    "        avg_cost+=cv/total_batch\n",
    "    print('cost:','{:.9f}'.format(avg_cost))\n",
    "\n",
    "c_pre=tf.equal(tf.argmax(hf, 1), tf.argmax(y,1))\n",
    "acc=tf.reduce_mean(tf.cast(c_pre, tf.float32))\n",
    "print('acc:', sess.run(acc, feed_dict=\n",
    "                       {x:mnist.test.images, \n",
    "                        y:mnist.test.labels,\n",
    "                       keep_prob:1}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "training_epochs=15\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #그래프에 있는 모든 텐서를 초기화\n",
    "x=tf.placeholder(tf.float32, [None, 28*28])\n",
    "ximg=tf.reshape(x, [-1, 28,28,1])# img 28*28*1(black)\n",
    "y=tf.placeholder(tf.float32,[None, 10])\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "L1=tf.nn.conv2d(ximg, w1, strides=[1,1,1,1],padding='SAME')\n",
    "L1=tf.nn.relu(L1)\n",
    "L1=tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "#L1 이미지 shape => (?, 7, 7, 32)\n",
    "\n",
    "\n",
    "w2=tf.Variable(tf.random_normal([3,3,32,64]))\n",
    "L2=tf.nn.conv2d(L1, w2, strides=[1,1,1,1],padding='SAME')\n",
    "L2=tf.nn.relu(L2)\n",
    "L2=tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "#conv2d(?, 14, 14, 64)\n",
    "#relu(?, 14, 14, 64)\n",
    "#max_pool(?, 7, 7, 64)\n",
    "L2_flat=tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "w3=tf.get_variable(\"w3\",shape=[7*7*64,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b=tf.Variable(tf.random_normal([10]))\n",
    "logits=tf.matmul(L2_flat, w3)+b\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n",
    "               (logits=logits, labels=y))\n",
    "train=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "              \n",
    "\n",
    "# w3=tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "# L3=tf.nn.conv2d(ximg, w1, strides=[1,1,1,1],padding='SAME')\n",
    "# L3=tf.nn.relu(L1)\n",
    "# L3=tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 1.018146217\n",
      "cost: 0.224454196\n",
      "cost: 0.149054128\n",
      "cost: 0.096512386\n",
      "cost: 0.069817956\n",
      "cost: 0.051579612\n",
      "cost: 0.042121376\n",
      "cost: 0.032592174\n",
      "cost: 0.032930480\n",
      "cost: 0.025344202\n",
      "cost: 0.022555416\n",
      "cost: 0.020489901\n",
      "cost: 0.017399357\n",
      "cost: 0.017112466\n",
      "cost: 0.013848557\n",
      "acc: 0.9842\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    total_batch=int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batchxs,batchys=mnist.train.next_batch(batch_size)\n",
    "        myfeed={x:batchxs, y:batchys}\n",
    "        cv,_=sess.run([cost, train], feed_dict=myfeed)\n",
    "        avg_cost+=cv/total_batch\n",
    "    print('cost:','{:.9f}'.format(avg_cost))\n",
    "\n",
    "c_pre=tf.equal(tf.argmax(logits, 1), tf.argmax(y,1))\n",
    "acc=tf.reduce_mean(tf.cast(c_pre, tf.float32))\n",
    "print('acc:', sess.run(acc, feed_dict=\n",
    "                       {x:mnist.test.images, \n",
    "                        y:mnist.test.labels,\n",
    "                      }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
