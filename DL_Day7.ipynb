{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Setosa' 'Versicolor' 'Virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x225fcb4cd30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"iris.csv\")\n",
    "len(data)\n",
    "data[:5]\n",
    "print(data['Species'].unique())\n",
    "import seaborn as sns\n",
    "sns.pairplot(data, hue='Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22581be1be0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data['Species'], data['sepal.width'],ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2258212d860>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data['Species'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Species']=data['Species'].replace(['Setosa','Versicolor','Virginica'],[0,1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x225821ab588>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Species'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "   sepal.length  sepal.width  petal.length  petal.width  Species\n",
      "0           5.1          3.5           1.4          0.2        0\n",
      "1           4.9          3.0           1.4          0.2        0\n",
      "2           4.7          3.2           1.3          0.2        0\n",
      "3           4.6          3.1           1.5          0.2        0\n",
      "4           5.0          3.6           1.4          0.2        0\n"
     ]
    }
   ],
   "source": [
    "#data.info()\n",
    "datax=data[['sepal.length', 'sepal.width','petal.length','petal.width']].values\n",
    "datay=data['Species'].values\n",
    "print(datax[:5])\n",
    "print(data[:5])\n",
    "\n",
    "#datay="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "(xtrain,xtest, ytrain,ytest)=train_test_split(datax,datay, train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "ytrain=np_utils.to_categorical(ytrain)\n",
    "ytest=np_utils.to_categorical(ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain\n",
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#소프트맥스 회귀\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 10:18:21.053448   244 deprecation_wrapper.py:119] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0814 10:18:21.098328   244 deprecation_wrapper.py:119] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0814 10:18:21.110300   244 deprecation_wrapper.py:119] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0814 10:18:21.169143   244 deprecation_wrapper.py:119] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0814 10:18:21.219004   244 deprecation_wrapper.py:119] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0814 10:18:21.400520   244 deprecation.py:323] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0814 10:18:21.487290   244 deprecation_wrapper.py:119] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/200\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 2.2278 - acc: 0.3667 - val_loss: 2.2478 - val_acc: 0.2000\n",
      "Epoch 2/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.7288 - acc: 0.3333 - val_loss: 1.7766 - val_acc: 0.1667\n",
      "Epoch 3/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.4101 - acc: 0.3333 - val_loss: 1.3977 - val_acc: 0.1667\n",
      "Epoch 4/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.1724 - acc: 0.3250 - val_loss: 1.1998 - val_acc: 0.1667\n",
      "Epoch 5/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0378 - acc: 0.3250 - val_loss: 1.0809 - val_acc: 0.1667\n",
      "Epoch 6/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.9620 - acc: 0.3667 - val_loss: 1.0007 - val_acc: 0.4000\n",
      "Epoch 7/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.9012 - acc: 0.5333 - val_loss: 0.9383 - val_acc: 0.5333\n",
      "Epoch 8/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.8505 - acc: 0.6583 - val_loss: 0.8869 - val_acc: 0.5333\n",
      "Epoch 9/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.8089 - acc: 0.6583 - val_loss: 0.8720 - val_acc: 0.5667\n",
      "Epoch 10/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.7733 - acc: 0.6833 - val_loss: 0.8358 - val_acc: 0.5667\n",
      "Epoch 11/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.7429 - acc: 0.6833 - val_loss: 0.7800 - val_acc: 0.5333\n",
      "Epoch 12/200\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.7141 - acc: 0.6750 - val_loss: 0.7667 - val_acc: 0.5333\n",
      "Epoch 13/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.6917 - val_loss: 0.7554 - val_acc: 0.5667\n",
      "Epoch 14/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6704 - acc: 0.7083 - val_loss: 0.7578 - val_acc: 0.5667\n",
      "Epoch 15/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6450 - acc: 0.6833 - val_loss: 0.7075 - val_acc: 0.5667\n",
      "Epoch 16/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6279 - acc: 0.6833 - val_loss: 0.6846 - val_acc: 0.5667\n",
      "Epoch 17/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.6127 - acc: 0.8000 - val_loss: 0.6778 - val_acc: 0.5667\n",
      "Epoch 18/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5969 - acc: 0.7167 - val_loss: 0.6651 - val_acc: 0.5667\n",
      "Epoch 19/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5835 - acc: 0.7417 - val_loss: 0.6427 - val_acc: 0.5667\n",
      "Epoch 20/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5741 - acc: 0.7167 - val_loss: 0.6431 - val_acc: 0.5667\n",
      "Epoch 21/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5610 - acc: 0.7250 - val_loss: 0.6304 - val_acc: 0.5667\n",
      "Epoch 22/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.5475 - acc: 0.7417 - val_loss: 0.6111 - val_acc: 0.5667\n",
      "Epoch 23/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5407 - acc: 0.7167 - val_loss: 0.5861 - val_acc: 0.6000\n",
      "Epoch 24/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5305 - acc: 0.8000 - val_loss: 0.5781 - val_acc: 0.6000\n",
      "Epoch 25/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5208 - acc: 0.7917 - val_loss: 0.5927 - val_acc: 0.5667\n",
      "Epoch 26/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5182 - acc: 0.7500 - val_loss: 0.5596 - val_acc: 0.6000\n",
      "Epoch 27/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5028 - acc: 0.8167 - val_loss: 0.5800 - val_acc: 0.5667\n",
      "Epoch 28/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4956 - acc: 0.7500 - val_loss: 0.5401 - val_acc: 0.6000\n",
      "Epoch 29/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4886 - acc: 0.8750 - val_loss: 0.5754 - val_acc: 0.6000\n",
      "Epoch 30/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4829 - acc: 0.7750 - val_loss: 0.5439 - val_acc: 0.6333\n",
      "Epoch 31/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.4807 - acc: 0.8000 - val_loss: 0.5525 - val_acc: 0.6000\n",
      "Epoch 32/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.4681 - acc: 0.8167 - val_loss: 0.5229 - val_acc: 0.6333\n",
      "Epoch 33/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4632 - acc: 0.8667 - val_loss: 0.5485 - val_acc: 0.6000\n",
      "Epoch 34/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.4611 - acc: 0.8000 - val_loss: 0.5219 - val_acc: 0.6333\n",
      "Epoch 35/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4542 - acc: 0.8333 - val_loss: 0.5219 - val_acc: 0.6333\n",
      "Epoch 36/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4462 - acc: 0.8000 - val_loss: 0.5072 - val_acc: 0.6333\n",
      "Epoch 37/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4410 - acc: 0.8833 - val_loss: 0.4939 - val_acc: 0.7000\n",
      "Epoch 38/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4359 - acc: 0.8500 - val_loss: 0.4999 - val_acc: 0.6333\n",
      "Epoch 39/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4315 - acc: 0.8833 - val_loss: 0.5055 - val_acc: 0.6333\n",
      "Epoch 40/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4287 - acc: 0.8583 - val_loss: 0.5110 - val_acc: 0.6667\n",
      "Epoch 41/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.4254 - acc: 0.8583 - val_loss: 0.4914 - val_acc: 0.6333\n",
      "Epoch 42/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4192 - acc: 0.8750 - val_loss: 0.4820 - val_acc: 0.6333\n",
      "Epoch 43/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4143 - acc: 0.8750 - val_loss: 0.4686 - val_acc: 0.7000\n",
      "Epoch 44/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4107 - acc: 0.8917 - val_loss: 0.4761 - val_acc: 0.6333\n",
      "Epoch 45/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4061 - acc: 0.8750 - val_loss: 0.4679 - val_acc: 0.7000\n",
      "Epoch 46/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4037 - acc: 0.9083 - val_loss: 0.4701 - val_acc: 0.6667\n",
      "Epoch 47/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3963 - acc: 0.9167 - val_loss: 0.4768 - val_acc: 0.6667\n",
      "Epoch 48/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3957 - acc: 0.8583 - val_loss: 0.4775 - val_acc: 0.6667\n",
      "Epoch 49/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3906 - acc: 0.8833 - val_loss: 0.4523 - val_acc: 0.7000\n",
      "Epoch 50/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3889 - acc: 0.9000 - val_loss: 0.4470 - val_acc: 0.7000\n",
      "Epoch 51/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.3829 - acc: 0.9000 - val_loss: 0.4380 - val_acc: 0.7000\n",
      "Epoch 52/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3818 - acc: 0.9167 - val_loss: 0.4532 - val_acc: 0.7333\n",
      "Epoch 53/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3747 - acc: 0.8917 - val_loss: 0.4249 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3740 - acc: 0.9000 - val_loss: 0.4239 - val_acc: 0.7333\n",
      "Epoch 55/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3697 - acc: 0.9333 - val_loss: 0.4276 - val_acc: 0.7000\n",
      "Epoch 56/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3687 - acc: 0.9250 - val_loss: 0.4408 - val_acc: 0.7333\n",
      "Epoch 57/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3662 - acc: 0.9333 - val_loss: 0.4374 - val_acc: 0.7333\n",
      "Epoch 58/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3602 - acc: 0.9333 - val_loss: 0.4318 - val_acc: 0.7333\n",
      "Epoch 59/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3560 - acc: 0.8917 - val_loss: 0.4210 - val_acc: 0.7333\n",
      "Epoch 60/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3544 - acc: 0.9333 - val_loss: 0.4194 - val_acc: 0.7333\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 1ms/step - loss: 0.3503 - acc: 0.9083 - val_loss: 0.4116 - val_acc: 0.7667\n",
      "Epoch 62/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3491 - acc: 0.9583 - val_loss: 0.4294 - val_acc: 0.7333\n",
      "Epoch 63/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3464 - acc: 0.8917 - val_loss: 0.4132 - val_acc: 0.7333\n",
      "Epoch 64/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3424 - acc: 0.9083 - val_loss: 0.3950 - val_acc: 0.8000\n",
      "Epoch 65/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3395 - acc: 0.9333 - val_loss: 0.4060 - val_acc: 0.7667\n",
      "Epoch 66/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3363 - acc: 0.9417 - val_loss: 0.4011 - val_acc: 0.7667\n",
      "Epoch 67/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3341 - acc: 0.9167 - val_loss: 0.3905 - val_acc: 0.8000\n",
      "Epoch 68/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3323 - acc: 0.9333 - val_loss: 0.3795 - val_acc: 0.8667\n",
      "Epoch 69/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3288 - acc: 0.9333 - val_loss: 0.3758 - val_acc: 0.8667\n",
      "Epoch 70/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3268 - acc: 0.9333 - val_loss: 0.3987 - val_acc: 0.7667\n",
      "Epoch 71/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.3246 - acc: 0.9417 - val_loss: 0.3878 - val_acc: 0.7667\n",
      "Epoch 72/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.3203 - acc: 0.9500 - val_loss: 0.3975 - val_acc: 0.7333\n",
      "Epoch 73/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3198 - acc: 0.9250 - val_loss: 0.3742 - val_acc: 0.9000\n",
      "Epoch 74/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3164 - acc: 0.9500 - val_loss: 0.3699 - val_acc: 0.9000\n",
      "Epoch 75/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3123 - acc: 0.9500 - val_loss: 0.3785 - val_acc: 0.8000\n",
      "Epoch 76/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3109 - acc: 0.9417 - val_loss: 0.3763 - val_acc: 0.8000\n",
      "Epoch 77/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3094 - acc: 0.9500 - val_loss: 0.3629 - val_acc: 0.9000\n",
      "Epoch 78/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3049 - acc: 0.9500 - val_loss: 0.3796 - val_acc: 0.7667\n",
      "Epoch 79/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3039 - acc: 0.9500 - val_loss: 0.3750 - val_acc: 0.7667\n",
      "Epoch 80/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3013 - acc: 0.9417 - val_loss: 0.3609 - val_acc: 0.9000\n",
      "Epoch 81/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2994 - acc: 0.9500 - val_loss: 0.3747 - val_acc: 0.7667\n",
      "Epoch 82/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2967 - acc: 0.9500 - val_loss: 0.3605 - val_acc: 0.8333\n",
      "Epoch 83/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2951 - acc: 0.9417 - val_loss: 0.3513 - val_acc: 0.9000\n",
      "Epoch 84/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2943 - acc: 0.9500 - val_loss: 0.3395 - val_acc: 0.9333\n",
      "Epoch 85/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.2899 - acc: 0.9667 - val_loss: 0.3571 - val_acc: 0.8333\n",
      "Epoch 86/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2883 - acc: 0.9667 - val_loss: 0.3616 - val_acc: 0.7667\n",
      "Epoch 87/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2866 - acc: 0.9500 - val_loss: 0.3452 - val_acc: 0.9000\n",
      "Epoch 88/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2850 - acc: 0.9833 - val_loss: 0.3478 - val_acc: 0.8667\n",
      "Epoch 89/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2827 - acc: 0.9667 - val_loss: 0.3502 - val_acc: 0.8333\n",
      "Epoch 90/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2840 - acc: 0.9500 - val_loss: 0.3290 - val_acc: 0.9333\n",
      "Epoch 91/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2790 - acc: 0.9583 - val_loss: 0.3447 - val_acc: 0.8667\n",
      "Epoch 92/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2758 - acc: 0.9583 - val_loss: 0.3448 - val_acc: 0.8667\n",
      "Epoch 93/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2763 - acc: 0.9500 - val_loss: 0.3310 - val_acc: 0.9333\n",
      "Epoch 94/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2731 - acc: 0.9583 - val_loss: 0.3311 - val_acc: 0.9333\n",
      "Epoch 95/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2703 - acc: 0.9750 - val_loss: 0.3421 - val_acc: 0.8333\n",
      "Epoch 96/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2696 - acc: 0.9583 - val_loss: 0.3200 - val_acc: 0.9333\n",
      "Epoch 97/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2665 - acc: 0.9750 - val_loss: 0.3268 - val_acc: 0.9333\n",
      "Epoch 98/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2649 - acc: 0.9667 - val_loss: 0.3294 - val_acc: 0.9000\n",
      "Epoch 99/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2625 - acc: 0.9583 - val_loss: 0.3207 - val_acc: 0.9333\n",
      "Epoch 100/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2629 - acc: 0.9750 - val_loss: 0.3309 - val_acc: 0.8667\n",
      "Epoch 101/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2604 - acc: 0.9583 - val_loss: 0.3157 - val_acc: 0.9333\n",
      "Epoch 102/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2598 - acc: 0.9667 - val_loss: 0.3054 - val_acc: 0.9333\n",
      "Epoch 103/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2600 - acc: 0.9667 - val_loss: 0.3274 - val_acc: 0.8667\n",
      "Epoch 104/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2551 - acc: 0.9667 - val_loss: 0.3156 - val_acc: 0.9333\n",
      "Epoch 105/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2543 - acc: 0.9750 - val_loss: 0.3111 - val_acc: 0.9333\n",
      "Epoch 106/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2523 - acc: 0.9750 - val_loss: 0.3238 - val_acc: 0.8667\n",
      "Epoch 107/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2510 - acc: 0.9750 - val_loss: 0.3269 - val_acc: 0.8667\n",
      "Epoch 108/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2515 - acc: 0.9583 - val_loss: 0.3062 - val_acc: 0.9333\n",
      "Epoch 109/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2465 - acc: 0.9583 - val_loss: 0.3038 - val_acc: 0.9333\n",
      "Epoch 110/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2452 - acc: 0.9667 - val_loss: 0.3051 - val_acc: 0.9333\n",
      "Epoch 111/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2433 - acc: 0.9667 - val_loss: 0.3146 - val_acc: 0.9000\n",
      "Epoch 112/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2430 - acc: 0.9583 - val_loss: 0.2987 - val_acc: 0.9333\n",
      "Epoch 113/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.9833 - val_loss: 0.3063 - val_acc: 0.9333\n",
      "Epoch 114/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2388 - acc: 0.9750 - val_loss: 0.2995 - val_acc: 0.9333\n",
      "Epoch 115/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2389 - acc: 0.9833 - val_loss: 0.2989 - val_acc: 0.9333\n",
      "Epoch 116/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2367 - acc: 0.9583 - val_loss: 0.2905 - val_acc: 0.9333\n",
      "Epoch 117/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2351 - acc: 0.9750 - val_loss: 0.3021 - val_acc: 0.9000\n",
      "Epoch 118/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2328 - acc: 0.9750 - val_loss: 0.2992 - val_acc: 0.9333\n",
      "Epoch 119/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2314 - acc: 0.9750 - val_loss: 0.2871 - val_acc: 0.9333\n",
      "Epoch 120/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2303 - acc: 0.9750 - val_loss: 0.2764 - val_acc: 0.9333\n",
      "Epoch 121/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2301 - acc: 0.9750 - val_loss: 0.2900 - val_acc: 0.9333\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2291 - acc: 0.9750 - val_loss: 0.3036 - val_acc: 0.9000\n",
      "Epoch 123/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2276 - acc: 0.9750 - val_loss: 0.2923 - val_acc: 0.9333\n",
      "Epoch 124/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2244 - acc: 0.9750 - val_loss: 0.2760 - val_acc: 0.9333\n",
      "Epoch 125/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2249 - acc: 0.9750 - val_loss: 0.2760 - val_acc: 0.9333\n",
      "Epoch 126/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2255 - acc: 0.9750 - val_loss: 0.2832 - val_acc: 0.9333\n",
      "Epoch 127/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2223 - acc: 0.9750 - val_loss: 0.2745 - val_acc: 0.9333\n",
      "Epoch 128/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2208 - acc: 0.9833 - val_loss: 0.2879 - val_acc: 0.9333\n",
      "Epoch 129/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2192 - acc: 0.9833 - val_loss: 0.2722 - val_acc: 0.9333\n",
      "Epoch 130/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2165 - acc: 0.9750 - val_loss: 0.2678 - val_acc: 0.9333\n",
      "Epoch 131/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2198 - acc: 0.9750 - val_loss: 0.2728 - val_acc: 0.9333\n",
      "Epoch 132/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2162 - acc: 0.9750 - val_loss: 0.2740 - val_acc: 0.9333\n",
      "Epoch 133/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2138 - acc: 0.9833 - val_loss: 0.2724 - val_acc: 0.9333\n",
      "Epoch 134/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2125 - acc: 0.9750 - val_loss: 0.2712 - val_acc: 0.9333\n",
      "Epoch 135/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2117 - acc: 0.9833 - val_loss: 0.2643 - val_acc: 0.9333\n",
      "Epoch 136/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2100 - acc: 0.9750 - val_loss: 0.2662 - val_acc: 0.9333\n",
      "Epoch 137/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2097 - acc: 0.9833 - val_loss: 0.2692 - val_acc: 0.9333\n",
      "Epoch 138/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2090 - acc: 0.9833 - val_loss: 0.2574 - val_acc: 0.9333\n",
      "Epoch 139/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2073 - acc: 0.9833 - val_loss: 0.2676 - val_acc: 0.9333\n",
      "Epoch 140/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2056 - acc: 0.9750 - val_loss: 0.2642 - val_acc: 0.9333\n",
      "Epoch 141/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2062 - acc: 0.9750 - val_loss: 0.2602 - val_acc: 0.9333\n",
      "Epoch 142/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2046 - acc: 0.9750 - val_loss: 0.2633 - val_acc: 0.9333\n",
      "Epoch 143/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.2021 - acc: 0.9750 - val_loss: 0.2671 - val_acc: 0.9333\n",
      "Epoch 144/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2022 - acc: 0.9750 - val_loss: 0.2632 - val_acc: 0.9333\n",
      "Epoch 145/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2012 - acc: 0.9750 - val_loss: 0.2541 - val_acc: 0.9333\n",
      "Epoch 146/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1999 - acc: 0.9833 - val_loss: 0.2620 - val_acc: 0.9333\n",
      "Epoch 147/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2004 - acc: 0.9750 - val_loss: 0.2533 - val_acc: 0.9333\n",
      "Epoch 148/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1973 - acc: 0.9750 - val_loss: 0.2519 - val_acc: 0.9333\n",
      "Epoch 149/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1975 - acc: 0.9750 - val_loss: 0.2524 - val_acc: 0.9333\n",
      "Epoch 150/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1953 - acc: 0.9667 - val_loss: 0.2415 - val_acc: 0.9667\n",
      "Epoch 151/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1945 - acc: 0.9833 - val_loss: 0.2506 - val_acc: 0.9333\n",
      "Epoch 152/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1930 - acc: 0.9750 - val_loss: 0.2512 - val_acc: 0.9333\n",
      "Epoch 153/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1935 - acc: 0.9750 - val_loss: 0.2443 - val_acc: 0.9333\n",
      "Epoch 154/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1915 - acc: 0.9833 - val_loss: 0.2455 - val_acc: 0.9333\n",
      "Epoch 155/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1901 - acc: 0.9833 - val_loss: 0.2504 - val_acc: 0.9333\n",
      "Epoch 156/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1893 - acc: 0.9750 - val_loss: 0.2420 - val_acc: 0.9333\n",
      "Epoch 157/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1907 - acc: 0.9750 - val_loss: 0.2385 - val_acc: 0.9667\n",
      "Epoch 158/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1897 - acc: 0.9833 - val_loss: 0.2264 - val_acc: 0.9667\n",
      "Epoch 159/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1883 - acc: 0.9750 - val_loss: 0.2414 - val_acc: 0.9333\n",
      "Epoch 160/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1855 - acc: 0.9833 - val_loss: 0.2358 - val_acc: 0.9667\n",
      "Epoch 161/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1859 - acc: 0.9750 - val_loss: 0.2329 - val_acc: 0.9667\n",
      "Epoch 162/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1850 - acc: 0.9833 - val_loss: 0.2290 - val_acc: 0.9667\n",
      "Epoch 163/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1857 - acc: 0.9833 - val_loss: 0.2315 - val_acc: 0.9667\n",
      "Epoch 164/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1842 - acc: 0.9750 - val_loss: 0.2390 - val_acc: 0.9333\n",
      "Epoch 165/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1834 - acc: 0.9833 - val_loss: 0.2287 - val_acc: 0.9667\n",
      "Epoch 166/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1812 - acc: 0.9750 - val_loss: 0.2324 - val_acc: 0.9667\n",
      "Epoch 167/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1807 - acc: 0.9833 - val_loss: 0.2256 - val_acc: 0.9667\n",
      "Epoch 168/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1794 - acc: 0.9750 - val_loss: 0.2342 - val_acc: 0.9333\n",
      "Epoch 169/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1785 - acc: 0.9833 - val_loss: 0.2292 - val_acc: 0.9667\n",
      "Epoch 170/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1770 - acc: 0.9750 - val_loss: 0.2228 - val_acc: 0.9667\n",
      "Epoch 171/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1797 - acc: 0.9750 - val_loss: 0.2223 - val_acc: 0.9667\n",
      "Epoch 172/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1766 - acc: 0.9833 - val_loss: 0.2238 - val_acc: 0.9667\n",
      "Epoch 173/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1767 - acc: 0.9833 - val_loss: 0.2273 - val_acc: 0.9667\n",
      "Epoch 174/200\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 0.1752 - acc: 0.9750 - val_loss: 0.2302 - val_acc: 0.9333\n",
      "Epoch 175/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1744 - acc: 0.9750 - val_loss: 0.2335 - val_acc: 0.9333\n",
      "Epoch 176/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1737 - acc: 0.9833 - val_loss: 0.2295 - val_acc: 0.9333\n",
      "Epoch 177/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1734 - acc: 0.9750 - val_loss: 0.2269 - val_acc: 0.9333\n",
      "Epoch 178/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1719 - acc: 0.9833 - val_loss: 0.2276 - val_acc: 0.9333\n",
      "Epoch 179/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1730 - acc: 0.9750 - val_loss: 0.2273 - val_acc: 0.9333\n",
      "Epoch 180/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1697 - acc: 0.9750 - val_loss: 0.2169 - val_acc: 0.9667\n",
      "Epoch 181/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1703 - acc: 0.9750 - val_loss: 0.2167 - val_acc: 0.9667\n",
      "Epoch 182/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1698 - acc: 0.9750 - val_loss: 0.2278 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1703 - acc: 0.9833 - val_loss: 0.2193 - val_acc: 0.9667\n",
      "Epoch 184/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1701 - acc: 0.9750 - val_loss: 0.2260 - val_acc: 0.9333\n",
      "Epoch 185/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1683 - acc: 0.9750 - val_loss: 0.2234 - val_acc: 0.9333\n",
      "Epoch 186/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1673 - acc: 0.9750 - val_loss: 0.2179 - val_acc: 0.9667\n",
      "Epoch 187/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1659 - acc: 0.9750 - val_loss: 0.2123 - val_acc: 0.9667\n",
      "Epoch 188/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1653 - acc: 0.9833 - val_loss: 0.2165 - val_acc: 0.9667\n",
      "Epoch 189/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1662 - acc: 0.9833 - val_loss: 0.2113 - val_acc: 0.9667\n",
      "Epoch 190/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1651 - acc: 0.9750 - val_loss: 0.2191 - val_acc: 0.9333\n",
      "Epoch 191/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1637 - acc: 0.9750 - val_loss: 0.2105 - val_acc: 0.9667\n",
      "Epoch 192/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1634 - acc: 0.9750 - val_loss: 0.2161 - val_acc: 0.9667\n",
      "Epoch 193/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1621 - acc: 0.9750 - val_loss: 0.2063 - val_acc: 0.9667\n",
      "Epoch 194/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1623 - acc: 0.9833 - val_loss: 0.2040 - val_acc: 0.9667\n",
      "Epoch 195/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1610 - acc: 0.9833 - val_loss: 0.2097 - val_acc: 0.9667\n",
      "Epoch 196/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1604 - acc: 0.9750 - val_loss: 0.2107 - val_acc: 0.9667\n",
      "Epoch 197/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1593 - acc: 0.9833 - val_loss: 0.2123 - val_acc: 0.9667\n",
      "Epoch 198/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1594 - acc: 0.9750 - val_loss: 0.2069 - val_acc: 0.9667\n",
      "Epoch 199/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1600 - acc: 0.9750 - val_loss: 0.1969 - val_acc: 0.9667\n",
      "Epoch 200/200\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.1583 - acc: 0.9833 - val_loss: 0.2016 - val_acc: 0.9667\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(3, input_dim=4, activation='softmax'))\n",
    "sgd=optimizers.SGD(lr=0.01) #학습률\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history=model.fit(xtrain,ytrain, batch_size=1, epochs=200, validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= range(1, len(history()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 33us/step\n",
      "테스트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(xtest,ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=4, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,input_dim=4, activation='relu', init='uniform'))\n",
    "#x=(1,4), W=(4,8), B=(1,8), y=(1,8)\n",
    "model.add(Dense(8, activation='relu'))\n",
    "#x=(1,8), W=(8,8), B=(1,8), y=(1,8)\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "#x=(1,8), W=(8,3), B=(1,3), y=(1,3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-56ec7024d83d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#배치경사하강법:1에폭에 모든 매개변수 업데이트를 한 번 수행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[0;32m    682\u001b[0m                                    \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, batch_size=len(xtrain))\n",
    "#배치경사하강법:1에폭에 모든 매개변수 업데이트를 한 번 수행\n",
    "\n",
    "model.fit(xtrain, ytrain, batch_size=16)\n",
    "\n",
    "model.fit(xtrain, ytrain, batch_size=1)\n",
    "#SGD(확률적 경사 하강법)\n",
    "\n",
    "keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'to': 7, 'live': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 6, 7, 8]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "t=Tokenizer()\n",
    "fitText=\"The earth is an awesome place to live\"\n",
    "t.fit_on_texts([fitText])\n",
    "print(t.word_index)\n",
    "\n",
    "test=\"The earth is an great place to live\"\n",
    "t.texts_to_sequences([test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30,  0,  0],\n",
       "       [40, 50,  0,  0,  0],\n",
       "       [60, 70, 80, 90,  0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding: 길이를 동일하게 맞춰주는 작업\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "pad_sequences([[10,20,30],[40,50],[60,70,80,90]], maxlen=5, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xinput' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1e4cb67af539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# model.evaluate(xtest, ytest, batch_size=32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxinput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#모델 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"my_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xinput' is not defined"
     ]
    }
   ],
   "source": [
    "# model.fit(xtrain, ytrain, epochs=10, batch_size=64)\n",
    "# model.evaluate(xtest, ytest, batch_size=32)\n",
    "\n",
    "model.predict(xinput, batch_size=32)\n",
    "#모델 저장\n",
    "model.save(\"my_model.h5\")\n",
    "#모델 불러오기\n",
    "from keras.models import load_model\n",
    "model=load_model(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15347241\n",
      "20 0.009408181\n",
      "40 0.0035546666\n",
      "60 0.0013430527\n",
      "80 0.0005074429\n",
      "100 0.00019172563\n",
      "120 7.243924e-05\n",
      "140 2.7368907e-05\n",
      "160 1.0340785e-05\n",
      "180 3.906789e-06\n",
      "200 1.4761517e-06\n",
      "220 5.5775735e-07\n",
      "240 2.1073741e-07\n",
      "260 7.963293e-08\n",
      "280 3.008144e-08\n",
      "300 1.1351105e-08\n",
      "320 4.294241e-09\n",
      "340 1.6279967e-09\n",
      "360 6.1381894e-10\n",
      "380 2.3129232e-10\n",
      "400 8.6895824e-11\n",
      "420 3.3008263e-11\n",
      "440 1.2468841e-11\n",
      "460 5.02709e-12\n",
      "480 1.9184654e-12\n",
      "500 7.8633394e-13\n",
      "520 2.9487524e-13\n",
      "540 1.373716e-13\n",
      "560 4.8553755e-14\n",
      "580 3.7895614e-14\n",
      "600 3.7895614e-14\n",
      "620 3.7895614e-14\n",
      "640 3.7895614e-14\n",
      "660 3.7895614e-14\n",
      "680 3.7895614e-14\n",
      "700 3.7895614e-14\n",
      "720 3.7895614e-14\n",
      "740 3.7895614e-14\n",
      "760 3.7895614e-14\n",
      "780 3.7895614e-14\n",
      "800 3.7895614e-14\n",
      "820 3.7895614e-14\n",
      "840 3.7895614e-14\n",
      "860 3.7895614e-14\n",
      "880 3.7895614e-14\n",
      "900 3.7895614e-14\n",
      "920 3.7895614e-14\n",
      "940 3.7895614e-14\n",
      "960 3.7895614e-14\n",
      "980 3.7895614e-14\n",
      "1000 3.7895614e-14\n",
      "1020 3.7895614e-14\n",
      "1040 3.7895614e-14\n",
      "1060 3.7895614e-14\n",
      "1080 3.7895614e-14\n",
      "1100 3.7895614e-14\n",
      "1120 3.7895614e-14\n",
      "1140 3.7895614e-14\n",
      "1160 3.7895614e-14\n",
      "1180 3.7895614e-14\n",
      "1200 3.7895614e-14\n",
      "1220 3.7895614e-14\n",
      "1240 3.7895614e-14\n",
      "1260 3.7895614e-14\n",
      "1280 3.7895614e-14\n",
      "1300 3.7895614e-14\n",
      "1320 3.7895614e-14\n",
      "1340 3.7895614e-14\n",
      "1360 3.7895614e-14\n",
      "1380 3.7895614e-14\n",
      "1400 3.7895614e-14\n",
      "1420 3.7895614e-14\n",
      "1440 3.7895614e-14\n",
      "1460 3.7895614e-14\n",
      "1480 3.7895614e-14\n",
      "1500 3.7895614e-14\n",
      "1520 3.7895614e-14\n",
      "1540 3.7895614e-14\n",
      "1560 3.7895614e-14\n",
      "1580 3.7895614e-14\n",
      "1600 3.7895614e-14\n",
      "1620 3.7895614e-14\n",
      "1640 3.7895614e-14\n",
      "1660 3.7895614e-14\n",
      "1680 3.7895614e-14\n",
      "1700 3.7895614e-14\n",
      "1720 3.7895614e-14\n",
      "1740 3.7895614e-14\n",
      "1760 3.7895614e-14\n",
      "1780 3.7895614e-14\n",
      "1800 3.7895614e-14\n",
      "1820 3.7895614e-14\n",
      "1840 3.7895614e-14\n",
      "1860 3.7895614e-14\n",
      "1880 3.7895614e-14\n",
      "1900 3.7895614e-14\n",
      "1920 3.7895614e-14\n",
      "1940 3.7895614e-14\n",
      "1960 3.7895614e-14\n",
      "1980 3.7895614e-14\n",
      "2000 3.7895614e-14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "xdata=[1,2,3]\n",
    "ydata=[1,2,3]\n",
    "\n",
    "x=tf.placeholder(tf.float32)\n",
    "y=tf.placeholder(tf.float32)\n",
    "\n",
    "w=tf.Variable(tf.random_normal([1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf=w*x+b\n",
    "cost=tf.reduce_mean((hf-y)**2)\n",
    "\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed={x:xdata, y:ydata}\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "for i in range(2001):\n",
    "    sess.run(train, feed_dict=feed)\n",
    "    if i%20==0:\n",
    "        print(i, sess.run(cost, feed_dict=feed))\n",
    "saver.save(sess, 'Model/first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.400744\n",
      "20 0.11020905\n",
      "40 0.04163995\n",
      "60 0.015732685\n",
      "80 0.0059442404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 13:57:06.483328   244 deprecation.py:323] From C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.0022458925\n",
      "120 0.00084856135\n",
      "140 0.00032060727\n",
      "160 0.0001211334\n",
      "180 4.576778e-05\n",
      "200 1.7292272e-05\n",
      "220 6.5331283e-06\n",
      "240 2.4682588e-06\n",
      "260 9.326765e-07\n",
      "280 3.5235237e-07\n",
      "300 1.3313314e-07\n",
      "320 5.0301082e-08\n",
      "340 1.9002854e-08\n",
      "360 7.1796884e-09\n",
      "380 2.7085132e-09\n",
      "400 1.0262559e-09\n",
      "420 3.8835898e-10\n",
      "440 1.4690708e-10\n",
      "460 5.648341e-11\n",
      "480 2.0923116e-11\n",
      "500 8.000711e-12\n",
      "520 3.0932294e-12\n",
      "540 1.1226575e-12\n",
      "560 4.92643e-13\n",
      "580 1.563194e-13\n",
      "600 6.158037e-14\n",
      "620 6.158037e-14\n",
      "640 1.8947807e-14\n",
      "660 4.7369517e-15\n",
      "680 0.0\n",
      "700 0.0\n",
      "720 0.0\n",
      "740 0.0\n",
      "760 0.0\n",
      "780 0.0\n",
      "800 0.0\n",
      "820 0.0\n",
      "840 0.0\n",
      "860 0.0\n",
      "880 0.0\n",
      "900 0.0\n",
      "920 0.0\n",
      "940 0.0\n",
      "960 0.0\n",
      "980 0.0\n",
      "1000 0.0\n",
      "1020 0.0\n",
      "1040 0.0\n",
      "1060 0.0\n",
      "1080 0.0\n",
      "1100 0.0\n",
      "1120 0.0\n",
      "1140 0.0\n",
      "1160 0.0\n",
      "1180 0.0\n",
      "1200 0.0\n",
      "1220 0.0\n",
      "1240 0.0\n",
      "1260 0.0\n",
      "1280 0.0\n",
      "1300 0.0\n",
      "1320 0.0\n",
      "1340 0.0\n",
      "1360 0.0\n",
      "1380 0.0\n",
      "1400 0.0\n",
      "1420 0.0\n",
      "1440 0.0\n",
      "1460 0.0\n",
      "1480 0.0\n",
      "1500 0.0\n",
      "1520 0.0\n",
      "1540 0.0\n",
      "1560 0.0\n",
      "1580 0.0\n",
      "1600 0.0\n",
      "1620 0.0\n",
      "1640 0.0\n",
      "1660 0.0\n",
      "1680 0.0\n",
      "1700 0.0\n",
      "1720 0.0\n",
      "1740 0.0\n",
      "1760 0.0\n",
      "1780 0.0\n",
      "1800 0.0\n",
      "1820 0.0\n",
      "1840 0.0\n",
      "1860 0.0\n",
      "1880 0.0\n",
      "1900 0.0\n",
      "1920 0.0\n",
      "1940 0.0\n",
      "1960 0.0\n",
      "1980 0.0\n",
      "2000 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model/first'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "xdata=[1,2,3]\n",
    "ydata=[1,2,3]\n",
    "\n",
    "x=tf.placeholder(tf.float32)\n",
    "y=tf.placeholder(tf.float32)\n",
    "\n",
    "w=tf.Variable(tf.random_normal([1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf=w*x+b\n",
    "cost=tf.reduce_mean((hf-y)**2)\n",
    "\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed={x:xdata, y:ydata}\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "for i in range(2001):\n",
    "    sess.run(train, feed_dict=feed)\n",
    "    if i%20==0:\n",
    "        print(i, sess.run(cost, feed_dict=feed))\n",
    "        saver.save(sess, 'Model/second', global_step=i)\n",
    "saver.save(sess, 'Model/first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\\first\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey Variable_10 not found in checkpoint\n\t [[node save_9/RestoreV2 (defined at <ipython-input-42-e08f585e50ea>:19) ]]\n\nOriginal stack trace for 'save_9/RestoreV2':\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-e08f585e50ea>\", line 19, in <module>\n    saver=tf.train.Saver()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 825, in __init__\n    self.build()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1779, in restore_v2\n    name=name)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key Variable_10 not found in checkpoint\n\t [[{{node save_9/RestoreV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1285\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1286\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key Variable_10 not found in checkpoint\n\t [[node save_9/RestoreV2 (defined at <ipython-input-42-e08f585e50ea>:19) ]]\n\nOriginal stack trace for 'save_9/RestoreV2':\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-e08f585e50ea>\", line 19, in <module>\n    saver=tf.train.Saver()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 825, in __init__\n    self.build()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1779, in restore_v2\n    name=name)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1295\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mnames_to_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[1;34m(checkpoint_path)\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1614\u001b[1;33m   \u001b[0mobject_graph_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1615\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[1;34m(self, tensor_str)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-e08f585e50ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhf\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1300\u001b[0m         \u001b[1;31m# a helpful message (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[1;32m-> 1302\u001b[1;33m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m       \u001b[1;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey Variable_10 not found in checkpoint\n\t [[node save_9/RestoreV2 (defined at <ipython-input-42-e08f585e50ea>:19) ]]\n\nOriginal stack trace for 'save_9/RestoreV2':\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-e08f585e50ea>\", line 19, in <module>\n    saver=tf.train.Saver()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 825, in __init__\n    self.build()\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1779, in restore_v2\n    name=name)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Kyujin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "xdata=[1,2,3]\n",
    "ydata=[1,2,3]\n",
    "\n",
    "x=tf.placeholder(tf.float32)\n",
    "y=tf.placeholder(tf.float32)\n",
    "\n",
    "w=tf.Variable(tf.random_normal([1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf=w*x+b\n",
    "cost=tf.reduce_mean((hf-y)**2)\n",
    "\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "sess=tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "feed={x:xdata, y:ydata}\n",
    "latest=tf.train.latest_checkpoint('Model')\n",
    "saver=tf.train.Saver()\n",
    "print(latest)\n",
    "saver.restore(sess,latest)\n",
    "print(sess.run(hf ,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "inputs=Input(shape=(10,))#입력 10개\n",
    "h1=Dense(64, activation='relu')(inputs)\n",
    "h2=Dense(64, activation='relu')(h1)\n",
    "output=Dense(1, activation='sigmoid')(h2)\n",
    "model=Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
